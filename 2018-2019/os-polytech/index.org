#+TITLE: Operate Resources in Public and Private Clouds
#+TITLE: Thanks to OpenStack
#+AUTHOR: Ronan-Alexandre Cherrueau, Adrien Lebre, Didier Iscovery
#+EMAIL: {firstname.lastname}@inria.fr
#+DATE: <2018-12-13 Thu>
#+STARTUP: entitiespretty
#+OPTIONS: ^:{} ':t email:t toc:nil
#+PROPERTY: header-args :mkdirp yes
#+HTML_DOCTYPE: html5
#+OPTIONS: html5-fancy:t
#+LINK: base-url https://rcherrueau.github.io/teaching/ptech18/%s
#+LINK: horizon-url  http://localhost/%s

#+EXCLUDE_TAGS: noexport
# #+EXCLUDE_TAGS: solution

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="org.css" />

#+BEGIN_abstract
OpenStack has become the de-facto solution to operate compute, network
and storage resources in public and private clouds. In this lab, we
are going to:
- Deploy an all-in-one OpenStack with [[https://github.com/CanonicalLtd/microstack][Snap microstack]].
- Operate this OpenStack to manage IaaS resources (e.g., boot VMs,
  setup a private Network).
- Deploys a Wordpress as a Service.
# - Automatize all the stuff with the Heat template engine (i.e., manage
#   your cloud from your sofa!).

Find the slides of the lecture [[file:docs/CloudFogEdgeIntro.pdf][here]] and [[file:docs/openstack-slides.pdf][there]].
#+END_abstract

#+TOC: headlines 3

* Table of Contents                                       :TOC_3_gh:noexport:
- [[#requirements-and-setup][Requirements and Setup]]
  - [[#resources-of-the-lab][Resources of the Lab]]
  - [[#environment][Environment]]
  - [[#setup-openstack][Setup OpenStack]]
- [[#play-with-openstack][Play with OpenStack]]
  - [[#openstack-horizon-dashboard][OpenStack Horizon Dashboard]]
  - [[#unleash-the-operator-in-you][Unleash the Operator in You]]
  - [[#in-encryption-we-trust][In Encryption We Trust]]
  - [[#the-art-of-provisioning-a-vm][The Art of Provisioning a VM]]
    - [[#debian-9-ftw][Debian 9 FTW]]
    - [[#cloudinit-in-action][Cloudinit in Action]]
- [[#deploy-a-wordpress-as-a-service][Deploy a Wordpress as a Service]]
  - [[#wordpress-mysql-database][Wordpress MySQL Database]]
  - [[#wordpress-application][Wordpress Application]]
- [[#appendix][Appendix]]
  - [[#installs-mariadb-on-debian-9][Installs MariaDB on Debian 9]]
  - [[#installs-wordpress-on-debian-9][Installs Wordpress on Debian 9]]

* Lecture Notes                                                    :noexport:
** Problem with Virtualbox
See https://github.com/CanonicalLtd/microstack/issues/41

Change ~/var/snap/microstack/common/etc/nova/nova.conf.d/hypervisor.conf~

#+BEGIN_SRC conf
[libvirt]
virt_type = qemu
cpu_mode = host-model
#+END_SRC

And restart ~nova-compute~

: sudo systemctl restart snap.microstack.nova-compute.service

** Export
Do ~C-c C-c~ on the following
#+BEGIN_SRC elisp :results none
(org-babel-tangle)
(org-ascii-export-to-ascii)
(org-html-export-to-html)
#+END_SRC

* Requirements and Setup
** Resources of the Lab
Get the resources of the lab at [[base-url:tp.tar.gz]].

#+BEGIN_SRC bash
curl -O https://rcherrueau.github.io/teaching/ptech18/tp.tar.gz
tar xf tp.tar.gz
cd ptech18
#+END_SRC

The archive contains:
- index.txt :: The current subject in text format.
- setup.sh :: Script that sets up the lab.
- teardown.sh :: Script that uninstalls the lab.
- rsc :: Resource directory with bash scripts useful for the lab.
- docs :: Slides of the lectures.

** Environment
To follow the lab you'll need a Linux (prefer Ubuntu 18.04) with 6 Go
of RAM and a few Go of disk.

The lab makes use of [[https://github.com/CanonicalLtd/microstack][Snap microstack]]: OpenStack in a Snap that you can
run locally on a single machine. Snap is the Canonical's App delivery
mechanism. It enables developers to bundle all dependencies into a
single app package. And so does Snap microstack for an all-in-one
OpenStack on your machine.

An all-in-one OpenStack means that your machine will contain both
services to /operate/ and /host/ virtualized resources. For instance,
the ~nova-conductor~ to operate the boot of a VM, and ~nova-compute~
to host the VM. Which is a good setup for a lab. There are several
other options such as [[https://docs.openstack.org/devstack/latest/index.html][DevStack]], [[https://docs.openstack.org/puppet-openstack-guide/latest/][Puppet-OpenStack]] or [[https://docs.openstack.org/developer/kolla-ansible/][Kolla-ansible]] and
all matters. But, Snap microstack takes only 2 minutes to deploy
OpenStack (instead of 30 minutes for other options).

#+BEGIN_note
- Devstack is good for OpenStack developers.
- Puppet-OpenStack or Kolla-ansible are good for production
  deployments.
#+END_note

** Setup OpenStack
Install snap.
: sudo apt install snapd

Install OpenStack directly from the snap store.
: sudo snap install microstack --classic --edge

Then, ensure OpenStack services are running on your machine.

#+BEGIN_do
Find the snap command that lists microstack OpenStack services and
there status? What is the purpose of each service?

#+BEGIN_solution
: snap services microstack

- glance-* :: Glance to manage VM images: ~openstack image --help~.
- horizon-* :: OpenStack Web dashboard: [[horizon-url]].
- keystone-* :: Keystone to manage authentication and authorization
                on OpenStack.
- neutron-* :: Neutron to manage networks: ~openstack network --help~.
- nova-* :: Nova to manage VM: ~openstack server --help~.
- memcached :: Cache used by all OpenStack services
- mysqld :: Database used by all OpenStack services
- rabbitmq-server :: Communication bus used by all OpenStack services
#+END_solution
#+END_do

And finally, execute the ~setup.sh~ file (require sudo).
: ./setup.sh

#+BEGIN_SRC bash :tangle ./setup.sh :shebang #!/usr/bin/env bash :exports none
sudo apt update
sudo apt install -y curl tcpdump
sudo snap install microstack --classic --edge
sudo snap install openstackclients --classic --edge
#+END_SRC

#+BEGIN_SRC bash :noweb tangle :tangle ./teardown.sh :shebang #!/usr/bin/env bash :exports none
. admin-openrc.sh

<<lst:delete-vms>>

<<lst:delete-fips>>

sudo snap remove openstackclients
sudo snap remove microstack
#+END_SRC

* Play with OpenStack
:PROPERTIES:
:CUSTOM_ID: sec:play-with-os
:END:
** OpenStack Horizon Dashboard
One service deployed is the OpenStack dashboard (Horizon). On your
machine horizon is reachable from the web browser at [[horizon-url]] with
the following credentials:
- login: ~admin~
- password: ~keystone~

From here, you can reach ~Project > Compute > Instances > Launch
Instance~ and boot a virtual machine given the following information:
- a name (e.g., ~horizon-vm~)
- an image (e.g., ~cirros~)
- a flavor to limit the resources of your instance (we recommend
  ~m1.tiny~)
- and a network setting (must be ~test~)

You should select options by clicking on the arrow on the right of
each possibility. When the configuration is OK, the ~Launch Instance~
button should be enabled. After clicking on it, you should see the
instance in the ~Active~ state in less than a minute.

Now, you have several options to connect to your freshly deployed VM.
For instance, by clicking on its name, Horizon provides a virtual
console under the tab ~Console~. Use the following credentials to
access the VM:
- login: ~cirros~
- password: ~cubswin:)~

Unfortunately this feature is disabled with Snap microstack. But as a
real DevOps, you will prefer to access to your vm by the command line
interface ...

** Unleash the Operator in You
While Horizon is helpful to discover OpenStack features, this is not
the tool of choice for a true operator. A true operator prefers
command line interface ðŸ˜„. You are lucky, OpenStack provides such a
command line interface.

To use it, you need in most deployments to set your environment with
the OpenStack credentials, so that the command line won't bother you
by requiring credentials each time. you can retrieve this information
through the Horizon interface by clicking on the ~admin~ dropdown list
at the top right corner and get the "OpenStack RC File V3" (or by
clicking on that [[horizon-url:project/api_access/openrc/][link]]).

To setup your environment please source this file.
: source ./admin-openrc.sh

You can then check that your environment is correctly set.
#+BEGIN_EXAMPLE
$ env|fgrep OS_|sort

OS_AUTH_URL=http://localhost:5000/v3/
OS_IDENTITY_API_VERSION=3
OS_INTERFACE=public
OS_PASSWORD=keystone
OS_PROJECT_DOMAIN_ID=default
OS_PROJECT_ID=76c02713292e4d3cba0625c9995a96aa
OS_PROJECT_NAME=admin
OS_REGION_NAME=microstack
OS_USER_DOMAIN_NAME=Default
OS_USERNAME=admin
#+END_EXAMPLE

All operations to manage OpenStack are done through one single command
line, called ~openstack~. Doing an ~openstack --help~ displays the
really long list of possibilities provided by this command. The
following gives you a selection of the most often used commands to
operate your Cloud:
- List OpenStack running services :: ~openstack endpoint list~
- List images :: ~openstack image list~
- List flavors :: ~openstack flavor list~
- List networks :: ~openstack network list~
- List computes :: ~openstack hypervisor list~
- List VMs (running or not) :: ~openstack server list~
- Get details on a specific VM :: ~openstack server show <vm-name>~
- Start a new VM :: ~openstack server create --image <image-name> --flavor <flavor-name> --nic net-id=<net-id> <vm-name>~
- View VMs logs :: ~openstack console log show <vm-name>~

Using all these commands, you can use the CLI to start a new tiny
cirros VM called ~cli-vm~:
#+BEGIN_SRC bash
openstack server create \
  --image cirros \
  --flavor m1.tiny \
  --network test \
  cli-vm
#+END_SRC

Then, display the information about your VM with the following
command:
: openstack server show cli-vm

Note in particular the ~status~ of your VM.
: openstack server show cli-vm -c status -f json

This status will go from ~BUILD~: OpenStack is looking for the best
place to boot the VM; to ~ACTIVE~: your VM is running (including the
boot phase). The status could also be ~ERROR~ if you are experiencing
hard times with your infrastructure.

Because an ~ACTIVE~ state includes the booting phase, you may wait for
one minute or two, the time for the VM finish booting. You can check
that by looking at its logs with ~openstack console log show cli-vm~.
The VM finished to boot when last lines are:
#+BEGIN_EXAMPLE
=== cirros: current=0.3.4 uptime=16.56 ===
  ____               ____  ____
 / __/ __ ____ ____ / __ \/ __/
/ /__ / // __// __// /_/ /\ \
\___//_//_/  /_/   \____/___/
   http://cirros-cloud.net


login as 'cirros' user. default password: 'cubswin:)'. use 'sudo' for root.
cli-vm login:
#+END_EXAMPLE

With the previous ~openstack server create~ command, the VM boots with
a private IP. Private IPs are used for communication between VMs,
meaning you cannot ping your VM from an external network (e.g., the
host machine). You have to manually affect a floating IP of the
~external~ network to your machine if you want it to be pingable from
the host.
#+BEGIN_SRC bash
ALLOCATED_FIP=$(openstack floating ip create \
  -c floating_ip_address -f value external)
openstack server add floating ip cli-vm "$ALLOCATED_FIP"
#+END_SRC

Then, ask again for the status of your VM and its IPs.
: openstack server show cli-vm -c status -c addresses

#+BEGIN_do
Note the new IP address. From which network this IP comes? Ping
~cli-vm~ on its floating IP.
: echo "$ALLOCATED_FIP"
: openstack subnet show external-subnet -c cidr -c allocation_pools
: ping "$ALLOCATED_FIP"

Does it work? Why? Hint: [[https://docs.openstack.org/neutron/latest/feature_classification/general_feature_support_matrix.html#operation_Security_Groups][OpenStack sets security groups by default]].

#+BEGIN_solution
The IP comes from the network 10.20.20.0/24 serves on the host machine
by ~br-ex~. Actually, Snap microstack [[https://github.com/CanonicalLtd/microstack/blob/130ff892b77b7a37268add7126216b31d3b5fd09/snap-overlay/bin/setup-br-ex][creates]] a new virtual interface
named ~br-ex~ to manage the external network.

: openstack subnet show external-subnet -c cidr -c allocation_pools
: ip a |fgrep -B 2 10.20.20

Regarding security rules, OpenStack is very conservative by default
and prevents ingress and egress traffic. The following rules allow
icmp packets and SSH connection on the VM.

#+BEGIN_SRC bash
SECGROUP_ID=`openstack security group list --project admin -f value -c ID`
openstack security group rule create $SECGROUP_ID --proto tcp --remote-ip 0.0.0.0/0 \
  --dst-port 22
openstack security group rule create $SECGROUP_ID --proto icmp --remote-ip 0.0.0.0/0
#+END_SRC
#+END_solution
#+END_do

Once you succeed to ping the vm, you should be able to SSH on it
: ssh -l cirros "$ALLOCATED_FIP"

#+BEGIN_do
From the cirros, ping the outside world.
: ping 8.8.8.8

Does it work? Why? Hint: do a ~tcpdump -nni br-ex icmp~ to understand
how the packets flow. Idem on the NIC of your default route.

#+BEGIN_solution
The network traffic on ~br-ex~ is not supposed to go out, and you have
to use the NIC of your default route (i.e., ~ip r|fgrep default~,
e.g., ~eth0~ ) as a gateway (see,
https://www.systutorials.com/1372/setting-up-gateway-using-iptables-and-route-on-linux/).

You have to change the source IP of out packet (~10.20.20.*~) to
gateway's IP (e.g., ~10.0.2.15~ on my machine). The ~iptables~ will
then automatically change the replied packet's destination IP
(~10.0.2.15~) to the original source IP (~10.20.20.*~). This process
is called a SNAT and you can implement it with ~iptables~.

First, enable Linux IP forwarding.
: sudo sysctl -w net.ipv4.ip_forward=1

Then, set up the SNAT with ~iptables~.
: sudo iptables -t nat -A POSTROUTING ! -d 10.20.20.0/24 -o eth0 -j SNAT --to-source 10.0.2.15
#+END_solution
#+END_do

Go on, and play with the ~openstack~ cli. For instance, list all
features offered by Nova with ~openstack server --help~ and try to
figure out how to:
1. SSH on ~cli-vm~ using its name rather than its IP;
2. Suspend and resume it;
3. Create a snapshot of ~cli-vm~;
4. Boot a new machine ~cli-vm-clone~ from the snapshot.
5. Delete ~cli-vm-clone~;

#+BEGIN_solution
#+BEGIN_SRC bash
# 1.
openstack server ssh cli-vm -l cirros
# 2.
openstack server suspend cli-vm; openstack server show cli-vm -c status
openstack server resume cli-vm; openstack server show cli-vm -c status
# 3.
openstack server image create --name cli-vm-img cli-vm; openstack image list
# 4.
openstack server create --wait --flavor m1.tiny \
  --network test --image cli-vm-img \
  cli-vm-clone
# 5.
openstack server delete cli-vm-clone
#+END_SRC
#+END_solution

** In Encryption We Trust
Any cirros VMs share the same credentials (i.e., ~cirros~, ~cubswin~)
which is a security problem. As an IaaS DevOps, you want that only
some clients can SSH on the VMs. Fortunately, OpenStack helps with the
management of SSH keys. OpenStack can generate a SSH key and push the
public counterpart on the VM. Therefore, doing a ~ssh~ on the VM will
use the SSH key instead of asking the client to fill the credentials.

Make an SSH key and store the private counterpart in =./admin.pem=.
Then, give that file the correct permission access.
: openstack keypair create --private-key ./admin.pem admin
: chmod 600 ./admin.pem

Start a new VM and ask OpenStack to copy the public counterpart of
your SSH key in the =~/.ssh/authorized_keys= of the VM (i.e., note the
~--key-name admin~).
#+BEGIN_SRC bash
openstack server create --wait --image cirros \
  --flavor m1.tiny --network test \
  --key-name admin cli-vm-adminkey
#+END_SRC

Attach it a floating IP.
#+BEGIN_SRC bash
openstack server add floating ip \
  cli-vm-adminkey \
  $(openstack floating ip create -c floating_ip_address -f value external)
#+END_SRC

Now you can access your VM using SSH without filling credentials.
#+BEGIN_SRC bash
openstack server ssh cli-vm-adminkey \
  --login cirros \
  --identity ./admin.pem
#+END_SRC

Or directly with the ~ssh~ command
: ssh -i ./admin.pem cirros@$(openstack server show cli-vm-adminkey -c addresses -f value | sed  -Er 's/test=.+ (10\.20\.20\.[0-9]+).*/\1/g')

#+BEGIN_NOTE
A regular ~ssh~ command looks like ~ssh -i <identity-file>
<name>@<server-ip>~. The following OpenStack command followed by the
~sed~ returns the floating IP of ~cli-vm-adminkey~. You may have to
adapt it a bit according to your network cidr.
: openstack server show cli-vm-adminkey -c addresses -f value | sed  -Er 's/test=.+ (10\.20\.20\.[0-9]+).*/\1/g'
#+END_NOTE

** The Art of Provisioning a VM
Provisioning is the process that automatically installs software,
alters configurations, and more on the machine as part of the boot
process. On OpenStack, provisioning is achieved thanks to [[https://cloud-init.io/][Cloudinit]].
It is a program that runs at the boot time to customize the VM.

You have already used Cloudinit without even knowing it! The previous
command ~openstack server create~ with the ~--identity~ parameter
tells OpenStack to make the public counterpart of the SSH key
available to the VM. When the VM boots for the first time, Cloudinit
is (among other tasks) in charge of fetching this public SSH key from
OpenStack, and copy it to =~/.ssh/authorized_keys=. Beyond that,
Cloudinit is in charge of many aspects of the VM customization like
mounting volume, resizing file systems or setting an hostname (the
list of Cloudinit modules can be found [[http://cloudinit.readthedocs.io/en/latest/topics/modules.html][here]]). Furthermore, Cloudinit
is able to run a bash script that will be executed on the VM as ~root~
during the boot process.

*** Debian 9 FTW
:PROPERTIES:
:CUSTOM_ID: sec:debian9-ftw
:END:
When it comes the time to deal with real applications, we cannot use
cirros VMs anymore. A Cirros VM is good for testing because it starts
fast and has a small memory footprint. However, do not expect to
launch MySQL or even [[https://github.com/busyloop/lolcat][~lolcat~]] on a cirros.

We are going to run several Debian9 VMs in this section. But, a
Debian9 takes a lot more of resources to run. For this reason, you
have to release all your resources before going further.

Delete currently running VMs.
#+NAME: lst:delete-vms
#+BEGIN_SRC bash
for vm in $(openstack server list -c Name -f value); do \
  echo "Deleting ${vm}..."; \
  openstack server delete "${vm}"; \
done
#+END_SRC

In the same manner, delete floating IPs.
#+NAME: lst:delete-fips
#+BEGIN_SRC bash
for ip in $(openstack floating ip list -c "Floating IP Address" -f value); do \
  echo "Deleting ${ip}..."; \
  openstack floating ip delete "${ip}"; \
done
#+END_SRC

Then, create a new flavor with 5 Go of Disk.
#+BEGIN_SRC bash
openstack flavor create --ram 2048 \
  --disk 5 --vcpus 1 --swap 1024 \
  --public m1.mini
#+END_SRC

Download the Debian9 image with support of Cloudinit.
#+BEGIN_SRC bash
curl -L -o /tmp/debian-9.qcow2 \
  https://cdimage.debian.org/cdimage/openstack/current-9/debian-9-openstack-amd64.qcow2
#+END_SRC

And import it into Glance.
#+BEGIN_SRC bash
openstack image create --disk-format=qcow2 \
  --container-format=bare --property architecture=x86_64 \
  --public --file /tmp/debian-9.qcow2 \
  debian-9
#+END_SRC

*** Cloudinit in Action
To tell Cloudinit to load and execute a specific script at boot time,
you have to add the extra argument ~--user-data
<file/path/of/your/script>~ at the regular ~openstack server create~
command.

#+BEGIN_do
Start a new VM named ~art-vm~ based on the ~debian-9~ image and the
~m1.mini~ flavor. The VM should load and execute the script [[lst:art.sh]]
-- available under [[file:rsc/art.sh]] -- that installs the [[https://github.com/cmatsuoka/figlet][~figlet~]] and
[[https://github.com/busyloop/lolcat][~lolcat~]] softwares on the VM.

#+CAPTION: Cloudinit script available under [[file:rsc/art.sh]]
#+NAME: lst:art.sh
#+BEGIN_SRC bash :tangle ./rsc/art.sh :shebang #!/usr/bin/env bash
# Fix DNS resolution
echo "" >> /etc/resolv.conf
echo "nameserver 8.8.8.8" >> /etc/resolv.conf

# Install figlet and lolcat
apt update
apt install -y figlet lolcat
#+END_SRC

You can follow the correct installation of software with:
: watch openstack console log show --lines=20 art-vm

#+BEGIN_solution
#+BEGIN_SRC bash
openstack server create --wait --image debian-9 \
  --flavor m1.mini --network test \
  --key-name admin \
  --user-data ./rsc/art.sh \
  art-vm
#+END_SRC
#+END_solution
#+END_do

Then, attach it a floating IP.
#+BEGIN_SRC bash
openstack server add floating ip \
  art-vm \
  $(openstack floating ip create -c floating_ip_address -f value external)
#+END_SRC

Hence, you can jump on the VM and call the ~figlet~ and ~lolcat~
software.
#+BEGIN_EXAMPLE
~$ openstack server ssh art-vm \
  --login debian \
  --identity ./admin.pem

The authenticity of host '10.20.20.13 (10.20.20.13)' can't be established.
ECDSA key fingerprint is SHA256:WgAn+/gWYg9MkauihPyQGwC0LJ8sLWM/ySrUzN8cK9w.
Are you sure you want to continue connecting (yes/no)? yes

debian@art-vm:~$ figlet "The Art of Provisionning a VM" | lolcat
#+END_EXAMPLE

* Deploy a Wordpress as a Service
[[https://wordpress.org/][Wordpress]] is the most popular content management system (CMS) in use
on the Web. People use it to create websites, blogs or applications.
It is open-source, and based on PHP and MySQL under the hood.

A common Wordpress deployment consists in two machines:
- ~wordpress-db~   :: A machine that contains the MySQL database for
     Wordpress.
- ~wordpress-app~  :: A machine that contains a web server and serves
     the Wordpress CMS.

The directory ~rsc~ provides bash scripts to deploy the MySQL database
and the web server. As the DevOps of OPH -- Online Polytech Hosting --
your job is to automatize the deployment of a Wordpress on your
OpenStack. See the bash scripts in [[*Appendix][appendix]] for more information.
Also, [[#sec:debian9-ftw][clean your environment]] before going further.

#+BEGIN_do
Make a bash script that automatically starts the ~wordpress-db~ and
~wordpress-app~ VM.
#+END_do

** Wordpress MySQL Database                                        :solution:
Start a VM with ~wordpress-db~ name, ~debian-9~ image, ~m1.mini~
flavor, ~test~ network and ~admin~ key-pair. Also, provision your VM
with the [[file:rsc/install-mariadb.sh]] script thanks to the ~--user-data
./rsc/install-mariadb.sh~ option.

#+BEGIN_SRC bash
openstack server create --wait --image debian-9 \
  --flavor m1.mini --network test \
  --key-name admin \
  --user-data ./rsc/install-mariadb.sh \
  wordpress-db
#+END_SRC

** Wordpress Application                                           :solution:
Start a VM with ~wordpress-app~ name, ~debian-9~ image, ~m1.mini~
flavor, ~test~ network and ~admin~ key-pair. Also, provision your VM
with the [[file:rsc/install-wp.sh]] script thanks to the ~--user-data
./rsc/install-wp.sh~ option. Note that you need to provide the IP
address of the ~wordpress-db~ to this script before running it.

Set the script with IP address of ~wordpress-db~.
#+BEGIN_SRC bash
sed -i '13s|.*|DB_HOST="'$(openstack server show wordpress-db -c addresses -f value | sed -Er "s/test=//g")'"|' ./rsc/install-wp.sh
#+END_SRC

Then, create ~wordpress-app~.
#+BEGIN_SRC bash
openstack server create --wait --image debian-9 \
  --flavor m1.mini --network test \
  --key-name admin \
  --user-data ./rsc/install-wp.sh \
  wordpress-app
#+END_SRC

Attach a floating ip to that VM.
#+BEGIN_SRC bash
openstack server add floating ip \
  wordpress-app \
  $(openstack floating ip create -c floating_ip_address -f value external)
#+END_SRC

Finally, you can reach WordPress on ~http://<floating-ip>/wp~.

* COMMENT Automatize the deployment with Heat
** Heat introduction
*** Introduction
In the previous sessions, we saw how to boot a VM with OpenStack, and execute a
post-installation script using the ~user-data~ mechanism. Such mechanism can
help us to install software but it is not enough to deploy a real Cloud
application. Cloud applications are composed of multiple services that
collaborate to deliver the application. Each service is a charge of an aspect of
the application. This separation of concerns brings flexibility. If a single
service is overloaded, it is common to deploy new units of this service to
balance the load.

Let's take a simple example! WordPress[fn:wordpress] is a very popular content
management system (CMS) written in PHP, which is mainly used as a blog system.
It is composed of two elements: a Web server (Apache) and a database (MySQL).
Apache serves the PHP code of WordPress and stores its information in the
database.

Automation is a very important concept for devops. Imagine you have your own
datacenter and want to exploit it by renting WordPress instances to your
customers. Each time a client rents an instance, you have to manually deploy it.
Wouldn't it more convenient to automate all the operations? :) To that end, we
are going to use an OpenStack project to automate the deployment of
applications: OpenStack Heat.

Heat is the OpenStack orchestrator: it eats templates (called HOT for Heat
Orchestration Template - which are files written in YAML) describing the
OpenStack infrastructure you want to deploy (e.g. vms, networks, storages) as
well as software configurations. Then the Heat engine is in charge of sending
the appropriate requests to OpenStack to deploy the system described in your
template (deployments are called ~stacks~ in Heat). In the following
subsections, we are going to manipulate Heat to understand how to deploy
applications on OpenStack. The following examples are extracted from the heat
templates you can find under the following directory:
~lib/heat_templates/debian/hello_world/~.

*** Boot a VM
The simplest HOT template your can declare describes how to boot a VM:

#+INCLUDE: "lib/heat_templates/debian/hello_world/1_boot_vm.yaml" src yaml

As depicted in this example, the different OpenStack resources can be declared
using types. OpenStack resource types are listed in the
documentation[fn:heat_resource_list], browsing this page, you can see that
resources exist for most OpenStack services (e.g. Nova, Neutron, Glance, Cinder,
Heat). Here, we declare a new resource called ~my_vm~ which is defined by the
type ~OS::Nova::Server~ to declare a new virtual machine. A type defines
different properties (some are mandatory, some are optional, see the
documentation for more details). The ~OS::Nova::Server~ properties should be
familiar to you since it is the classical properties Nova requires to boot a VM
(i.e. a name, an image, a flavor, a key name). Once you have written this
template in a file, you can now deploy the stack as following:

#+BEGIN_SRC bash
$ openstack stack create -t ./1_boot_vm.yaml hw1
$ openstack stack list
$ openstack stack show hw1
$ watch openstack server list
$ openstack server ssh --login debian --identity ./admin.pem --address-type provider-net hello_world
$ openstack stack delete hw1
#+END_SRC

This simple template is enough to run a virtual machine. However it is very
static. In the next subsection, we are going to manipulate parameters to add
flexibility.

*** Need more flexibility: let's add parameters!

Templates can be more flexible with parameters. To that end you can:
- declare a set of parameters to provide to your template;
- use the intrinsic function ~get_param~ to map those parameters in your
  resource declarations.
Here's an example:

#+INCLUDE: "lib/heat_templates/debian/hello_world/2_boot_vm_with_params.yaml" src yaml

In this example, we defined two parameters. While the first one related to the
VM flavor has a default value (i.e. ~m1.small~), the second one, corresponding
to the name of the key pair to use, must be provided. To deploy this stack, run
the following command:

#+BEGIN_SRC bash
$ openstack stack create -t ./2_boot_vm_with_params.yaml \
    --parameter param_name=hello_params \
    --parameter param_flavor=m1.medium \
    hw2
$ openstack server list
$ openstack stack delete hw2
#+END_SRC

This command deploys our VM by overriding the default flavor value ~m1.small~ by
~m1.medium~. This can be checked by typing: ~openstack server list~. The
parameter ~param_name~ is required and no default value is provided. As such, if
you try to create a stack without providing this parameter, you would the
following error:

#+BEGIN_SRC bash
$ openstack stack create -t ./2_boot_vm_with_params.yaml \
    --parameter param_flavor=m1.medium \
    hw2_error
ERROR: The Parameter (param_name) was not provided.
#+END_SRC

Parameters are the inputs of our templates. In the next subsection, we are going
to see how templates can declare outputs, so that our stacks can return a set of
attributes (e.g. the IP address of a deployed VM).

*** Need our deployment to return values: let's use outputs!
Templates can declare a set of attributes to return. For instance, you might
need to know the IP address of a resource at run-time. To that end, you can
declare attributes in a new section called ~outputs~:

#+INCLUDE: "lib/heat_templates/debian/hello_world/3_boot_vm_with_output.yaml" src yaml

We declared here an output attribute called ~HOSTIP~ which stores the IP address
of the VM resource. We used here another intrinsic function which is used to get
the IP address from our VM: ~get_attr~. Output attributes can be exploited in
two ways: it can be displayed from the CLI, or it can be fetched by other stack
templates (we will see this last case latter):

#+BEGIN_SRC bash
$ openstack stack create -t ./3_boot_vm_with_output.yaml hw3
$ openstack stack output list hw3
$ openstack stack output show hw3 HOSTIP
$ openstack stack delete hw3
#+END_SRC

*** Integrate ~cloud-init~ in Heat
It is possible to declare a post-installation script in the template with
the user-data property:

#+INCLUDE: "lib/heat_templates/debian/hello_world/4_boot_vm_with_user-data.yaml" src yaml

#+BEGIN_SRC bash
$ openstack stack create -t ./4_boot_vm_with_user-data.yaml hw4
$ openstack server ssh --login debian --identity ./admin.pem --address-type provider-net hw4
$ openstack stack delete hw4
#+END_SRC

*** Dynamic configuration with ~cloud-init~ and parameters
Let's mix the capabilities we learned from the parameter and cloud-init
templates to write a template with a flexible post-installation script. With
Heat, it is possible to provide a parameter to your user-data at run-time by
using a new function: ~str_replace~!

#+INCLUDE: "lib/heat_templates/debian/hello_world/5_boot_vm_with_user-data2.yaml" src yaml

We used here the new intrinsic function ~str_replace~ to replace strings in our
user-data. In this example, the parameter should be a string containing a set of
packages to install in the VM. You can deploy the stack as follow:

#+BEGIN_SRC bash
$ openstack stack create \
    -t ./5_boot_vm_with_user-data2.yaml \
    --parameter PackageName="vim cowsay fortune fortunes" \
   hw5
#+END_SRC

This mechanism is crucial to dynamically configure our services during the
deployment. For instance, Service_A might require an IP address in its
configuration file to access Service_B, which runs on another VM. This IP
address is only known at run-time, so it must be represented by a variable
managed in Heat templates. In the next subsections, we are going to study how to
declare such variable, so that Heat resources can exchange information.

*** Data dependency between resources
Let's declare a template with two VMs: ~provider~ and ~user~. The idea is to
configure user's static lookup table for hostnames (more information can be
found by typing: ~man hosts~), so that user can target provider from its
hostname rather than from its IP address. To that end, we will use the user-data
mechanism to edit the ~/etc/hosts~ file on user, and map the IP address of
provider with its hostname:

#+INCLUDE: "lib/heat_templates/debian/hello_world/6_boot_vms_with_exchange.yaml" src yaml

In this example, ~user~ requires the IP address of ~provider~ to boot. The Heat
engine is in charge of managing dependencies between resources. Take a look
during the deployment, and check that ~provider~ is deployed prior ~user~:

#+BEGIN_SRC bash
$ openstack stack create -t ./6_boot_vms_with_exchange.yaml hw6 && watch openstack server list
$ openstack server ssh --login debian --identity ./admin.pem --address-type provider-net user
debian@user:~$ ping provider
debian@user:~$ exit
$ openstack stack delete hw6
#+END_SRC

*** Nested templates
Heat is able to compose templates to keep human-readable files, using nested
templates. For instance, we can use a first template that describes a virtual
machine, and a second template which deploys multiple VMs by referencing the
first one. Rather than create the first template, we can re-use
~2_boot_vm_with_params.yaml~:

#+INCLUDE: "lib/heat_templates/debian/hello_world/7_nested_template.yaml" src yaml

To compose template, a new resource can be defined by specifying its type as the
target of the desired template. A set of properties can be provided to the
nested template and will be interpreted as parameters.

Nested templates are very convenient to keep your code clean and re-use
templates. We are now reaching the last subsection, where we are going to extend
nested templates with data dependency.

** Nested templates with data dependency

Let's describe the same deployment as in `Data dependency between resources` by
using nested templates. For that we need a new template:

#+INCLUDE: "lib/heat_templates/debian/hello_world/8_nested_template_boot_vm.yaml" src yaml

We can now declare the main template. While it defines three VMs, this template
is easy to read since it points to the template created previously, and
~3_boot_vm_with_output.yaml~:

#+INCLUDE: "lib/heat_templates/debian/hello_world/8_nested_template_exchange.yaml" src yaml

** Automatic deployment of WordPress with Heat
As a DevOps at OMH, you are now in charge of the automation process of deploying
WordPress instances for clients. Congratulation! To that end, you have to use
what you learned from the previous section to design a template that describes a
WordPress application using Heat. We are going to deploy WordPress inside two
VMs: the first one holds the web server, the second one runs the database:

- VM1: Apache + PHP + WordPress code
- VM2: MySQL

It is highly recommended that you create three HOT files:

- ~sql_vm.yml~: containing the description of the VM running MySQL;
- ~web_vm.yml~: containing the description of the VM running the Web server;
- ~wp_app.yml~: containing the description of the WordPress application
  (~sql_vm.yml~ + ~web_vm.yml~ as nested templates).

To help you, we provide the post-installation script for both VMs. You should
read them to understand what they do. Here's the first one is related to the
database:

#+INCLUDE: "lib/mariadb.sh" src yaml

Here's the one for the web server:

#+INCLUDE: "lib/apache2.sh" src yaml

Once it is deployed, you should be able to reach the wordpress service by
typing:

#+BEGIN_SRC bash
$ lynx <web_server_ip_address>/wp
#+END_SRC

* Appendix
** Installs MariaDB on Debian 9
#+INCLUDE: "rsc/install-mariadb.sh" src bash

** Installs Wordpress on Debian 9
#+INCLUDE: "rsc/install-wp.sh" src bash

* Local Variables                                                  :noexport:
# Local Variables:
# org-html-postamble: "<p class=\"author\">Author: %a</p>
# <p class=\"email\">Email: %e</p>
# <p class=\"github\">Find a typo, wanna make a proposition:
#  <a href=\"https://github.com/BeyondTheClouds/lectures/issues/new?title=[ptech18]\">open an issue</a></p>
# <p class=\"date\">Last modification: %C</p>
# <p class=\"license\">This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
# <p class=\"creator\">%c â€“ theme by
#  <a href=\"http://gongzhitaao.org/orgcss\">http://gongzhitaao.org/orgcss</a></p>"
# End:
