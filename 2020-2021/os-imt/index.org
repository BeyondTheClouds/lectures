#+TITLE: Operate Resources in Public and Private Clouds
#+TITLE: Thanks to OpenStack
#+AUTHOR: Ronan-Alexandre Cherrueau, Adrien Lebre, Didier Iscovery
#+EMAIL: {firstname.lastname}@inria.fr
#+DATE: [2020-11-09 Mon]

#+BEGIN_abstract
OpenStack has become the de-facto solution to operate compute, network
and storage resources in public and private clouds. In this lab, we
are going to:
- Deploy an all-in-one OpenStack with [[https://opendev.org/x/microstack/][Snap microstack]].
- Operate this OpenStack to manage IaaS resources (e.g., boot VMs,
  setup a private Network).
- Deploys a Wordpress as a Service.
- Automatize all the stuff with the Heat template engine (i.e., manage
  your cloud from your sofa!).

Find the slides of the lecture [[cdn-url:2018-2019/os-polytech/docs/CloudFogEdgeIntro.pdf][here]] and [[cdn-url:2018-2019/os-polytech/docs/openstack-slides.pdf][there]].
# This document is an [[https://orgmode.org/][Org mode]] document, you can find its source [[cdn-url:index.org][here]].
#+END_abstract

#+TOC: headlines 3

* Table of Contents                                       :TOC_3_gh:noexport:
- [[#requirements-and-setup][Requirements and Setup]]
  - [[#environment][Environment]]
  - [[#access-the-lab-machine][Access the Lab machine]]
  - [[#resources-of-the-lab][Resources of the Lab]]
  - [[#setup-openstack][Setup OpenStack]]
- [[#play-with-openstack-as-an-admin][Play with OpenStack (as an Admin)]]
  - [[#openstack-horizon-dashboard][OpenStack Horizon dashboard]]
  - [[#unleash-the-operator-in-you][Unleash the operator in you]]
    - [[#make-the-world-reaches-the-vm][Make the world reaches the VM]]
  - [[#in-encryption-we-trust][In encryption we trust]]
  - [[#the-art-of-contextualizing-a-vm][The art of contextualizing a VM]]
    - [[#debian-10-ftw][Debian 10 FTW]]
    - [[#cloud-init-in-action][~cloud-init~ in Action]]
  - [[#run-vms-at-near-native-speed][Run VMs at (near-)native speed]]
- [[#deploy-a-wordpress-as-a-service-as-a-devops][Deploy a WordPress as a Service (as a DevOps)]]
- [[#automatize-the-deployment-with-heat][Automatize the Deployment with Heat]]
  - [[#preamble][Preamble]]
  - [[#boot-a-vm][Boot a VM]]
  - [[#need-more-flexibility-lets-add-parameters][Need more flexibility: let's add parameters]]
  - [[#need-to-return-values-lets-use-outputs][Need to return values: let's use outputs!]]
  - [[#integrate-cloud-init][Integrate ~cloud-init~]]
  - [[#dynamic-configuration-with-cloud-init-and-parameters][Dynamic configuration with ~cloud-init~ and parameters]]
  - [[#data-dependency-between-resources][Data dependency between resources]]
  - [[#nested-templates][Nested templates]]
  - [[#nested-templates-with-data-dependency][Nested templates with data dependency]]
  - [[#other-type-of-resources-floating-ip][Other type of resources: floating IP]]
- [[#deploy-a-wordpress-as-a-service-as-a-heat-devops][Deploy a WordPress as a Service (as a Heat DevOps)]]
  - [[#database-vm-template][Database VM template]]
  - [[#web-vm-template][Web VM template]]
  - [[#wordpress-application-template][Wordpress application template]]
- [[#appendix][Appendix]]
  - [[#install-mariadb-on-debian-10][Install MariaDB on Debian 10]]
  - [[#install-wordpress-application-on-debian-10][Install Wordpress application on Debian 10]]
- [[#footnotes][Footnotes]]

* Lecture Notes for the Teacher                                    :noexport:
Do ~C-c C-c~ in the following to export and publish the Lab after
reviewing the [[lst:export]] and [[lst:publish]] scripts.

#+BEGIN_SRC elisp :results silent :noweb yes
<<lst:export>>
<<lst:publish>>
#+END_SRC

** Export
Do ~C-c C-c~ in the following
#+NAME: lst:export
#+BEGIN_SRC elisp :results silent :noweb yes
(let* ((output-dir "output")
       (outfile.txt (org-export-output-file-name ".txt" nil output-dir))
       (outfile.html (org-export-output-file-name ".html" nil output-dir)))

  ;; Clean everything
  (delete-directory output-dir t)

  ;; Export subject and source code
  (make-directory output-dir)
  (org-export-to-file 'ascii outfile.txt)
  (org-export-to-file 'html outfile.html)
  (org-babel-tangle)

  ;; Make the tp.tar.gz
  (shell-command (format "tar czf tp.tar.gz --transform 's|^%s|tp|' %s"
                         output-dir output-dir)))
#+END_SRC

** Publish
Do ~C-c C-c~ in the following.

Put it on my personal website.
#+NAME: lst:publish
#+BEGIN_SRC elisp :results silent :noweb yes
(let* ((base-dir "~/prog/rcherrueau.github.com/teaching/")
       (export-dir (concat base-dir "2020-2021/os-imt/")))
  ;; Delete export if it exists. Always start from the ground base.
  (when (file-directory-p export-dir)
    (delete-directory export-dir t))

  ;; Create directory and copy index files
  (make-directory export-dir)
  (shell-command (format "cp -r output/index.html %s" export-dir)))
#+END_SRC

** Hide/show solutions
Do ~C-c C-c~ in one of the followings.

Hide solutions
#+BEGIN_SRC elisp :results silent :noweb yes
(save-excursion
  (while (re-search-forward "\\(BEGIN\\|END\\)_solution" nil t)
    (replace-match "\\1_comment\n# solution"))
  (save-buffer))
#+END_SRC

Show solutions
#+BEGIN_SRC elisp :results silent :noweb yes
(save-excursion
  (while (re-search-forward "\\(BEGIN\\|END\\)_comment\n# solution" nil t)
    (replace-match "\\1_solution"))
  (save-buffer))
#+END_SRC

* Requirements and Setup
:PROPERTIES:
:CUSTOM_ID: sec:req
:END:
** Environment
OpenStack needs, at least, 6 Go of RAM to run. And plenty more to
start VMs on it. Therefore, this lab relies on [[https://www.grid5000.fr/][Grid'5000]], a testbed
for experimental research, to acquire a /Lab machine/ larger than your
personal one. The Lab machine is a Ubuntu20.04 with 128Go of RAM and
32 CPU cores. This should be enough resources for this lab!

The lab makes use of [[https://github.com/CanonicalLtd/microstack][Snap microstack]]: OpenStack in a Snap that you can
run locally on a single machine. Snap is the Canonical's App delivery
mechanism. It enables developers to bundle all dependencies into a
single app package. And so does Snap microstack for an all-in-one
OpenStack on your machine.

An all-in-one OpenStack means that your machine will contain both
services to /operate/ and /host/ virtualized resources. For instance,
the ~nova-conductor~ to operate the boot of a VM, and ~nova-compute~
to host the VM. This is a good setup for a lab, but not for
production. There are several other options such as [[https://docs.openstack.org/devstack/latest/index.html][DevStack]],
[[https://docs.openstack.org/puppet-openstack-guide/latest/][Puppet-OpenStack]] or [[https://docs.openstack.org/developer/kolla-ansible/][Kolla-ansible]] and all matters. But, Snap
microstack takes only 2 minutes to deploy OpenStack (instead of 30
minutes for other options).

#+BEGIN_note
- Devstack is good for OpenStack developers.
- Puppet-OpenStack or Kolla-ansible are good for production
  deployments.
#+END_note

** Access the Lab machine
:PROPERTIES:
:CUSTOM_ID: sec:assign-lab
:END:
Here is the assignation list of Lab machine per team:
- ronana, alebre :: ~172.16.193.13~

First thing first, you have to connect to the Lab machine.
Unfortunately, the Lab machine isn't available publicly, but hides
behind the Grid'5000 private network. One solution, as explained in
the [[https://www.grid5000.fr/mediawiki/index.php/Getting_Started#Connecting_for_the_first_time][official tutorial]], consists in opening an SSH connection to the
publicly available ~access.grid5000.fr~ machine, and from there, doing
a second SSH connection to the Lab machine. But this solution is
fairly limited since it doesn't give an access to services from your
own machine[fn:g5k-tunnel].

To ease the interaction between your own machine and the Lab one, you
should setup the Grid'5000 [[https://en.wikipedia.org/wiki/Virtual_private_network][VPN]]. The Grid'5000 VPN gives you access to
the Grid'5000 private network and thus, Lab machines wherever your are
on the globe.

Next gives you the procedure on Ubuntu, but should be similar on other
UNIX systems. You can also do it on Windows, however expect to be on
your own in case of troubles.

1. Install the [[https://openvpn.net/][OpenVPN]] client
   : sudo apt update -y && apt install -y openvpn
3. Go on [[https://api.grid5000.fr/stable/users/][UMS]] > "My Account" tab > "VPN certificates" item.
4. "Create new certificate" > "Create with passphrase", and fill the
   form with a new password (remember it!).
5. Click on "Zip file" Action > store it somewhere on your personal
   machine > unzip it. If the ~unzip~ program is unavailable, install
   it with ~sudo apt install unzip~.
   : unzip <g5k_login>_vpnclient.zip -d g5k_vpnclient
6. Run OpenVPN client with sudo
   : cd g5k_vpnclient; sudo openvpn Grid5000_VPN.ovpn
7. Fill password of step 4 to the question ~Enter Private Key
   Password:~.

You correctly setup the VPN and can access Grid'5000 private network
if your shell hangs and you see the following route in your routing
table.
#+begin_src bash
$ ip route

# ...
10.0.0.0/8 via 172.20.255.254 dev tun0
172.16.0.0/16 via 172.20.255.254 dev tun0
172.20.0.0/16 via 172.20.255.254 dev tun0
172.20.192.0/18 dev tun0 proto kernel scope link src 172.20.192.5
# ...
#+end_src

You can finally connect to your Lab machine in another shell with the
following SSH command. Use ~os-imt~ as password.
: ssh -l root <ip-of-your-lab-machine>

The rest of this lab *proceeds on the Lab machine*.

** Resources of the Lab
:PROPERTIES:
:CUSTOM_ID: sec:rscs-lab
:END:
Get the resources of the lab at [[cdn-url:2020-2021/os-imt/tp.tar.gz]].

#+BEGIN_SRC bash
curl https://github.com/BeyondTheClouds/lectures/blob/f65ea63/2020-2021/os-imt/tp.tar.gz?raw=true -o tp.tar.gz -L
mkdir ~/os-imt
tar xzf tp.tar.gz -C ~/os-imt
cd ~/os-imt
#+END_SRC

The archive contains:
- setup.sh :: Script that sets up the lab.
- teardown.sh :: Script that uninstalls the lab.
- rsc :: Resource directory with bash scripts useful for the lab.

** Setup OpenStack
Install snap.
: sudo apt update
: sudo apt install snapd

Install OpenStack directly from the snap store.
: sudo snap install --channel=latest/beta microstack --devmode

Execute the ~setup.sh~ file with sudo to initialize OpenStack (setup
networks, flavors, images, ...).
: sudo ./setup.sh

#+BEGIN_do
Then, ensure OpenStack services are running on your machine. Find the
snap command that lists microstack OpenStack services and there
status? What is the purpose of each service?

#+BEGIN_comment
# solution
: snap services microstack|sort

- glance-* :: Glance to manage VM images: ~openstack image --help~.
- horizon-* :: OpenStack Web dashboard: [[http://<ip-of-your-lab-machine>]].
- keystone-* :: Keystone to manage authentication and authorization
                on OpenStack.
- neutron-* :: Neutron to manage networks: ~openstack network --help~.
- nova-* :: Nova to manage VM: ~openstack server --help~.
- memcached :: Cache used by all OpenStack services
- mysqld :: Database used by all OpenStack services
- rabbitmq-server :: Communication bus used by all OpenStack services
#+END_comment
# solution
#+END_do

*** Setup script                                                   :noexport:
#+BEGIN_SRC bash :noweb tangle :tangle output/setup.sh :shebang #!/usr/bin/env bash
set -o errexit
set -o xtrace

# Set the admin password to keystone
snap set microstack config.credentials.keystone-password=keystone
snap set microstack config.host.check-qemu=False

# Initialize  OpenStack
microstack.init --auto --control

# Make nova use qemu instead of qemu-kvm
# i.e,:
# > [libvirt]
# > virt_type = kvm             # rewrite to qemu
# > cpu_mode = host-passthrough # rewrite to host-model
NOVA_HYPERV_CONF=/var/snap/microstack/common/etc/nova/nova.conf.d/hypervisor.conf
sed -i 's|virt_type.\+|virt_type = qemu|' $NOVA_HYPERV_CONF
sed -i 's|cpu_mode.\+|cpu_mode = host-model|' $NOVA_HYPERV_CONF
snap restart microstack.nova-compute

# Install the bare necessities
apt install --yes --quiet silversearcher-ag curl tcpdump kmod vim htop
snap install --channel=latest/stable openstackclients --classic

# Put snap openstackclients into the path.
export PATH=/snap/bin:$PATH

set +o xtrace

# Remove icmp and tcp security group rules of `microstack.init --auto`
for rule in $(microstack.openstack security group rule list --protocol icmp -c ID -f value)
do
    microstack.openstack security group rule delete "${rule}"
done
for rule in $(microstack.openstack security group rule list --protocol tcp -c ID -f value)
do
    microstack.openstack security group rule delete "${rule}"
done

# Do not include this for IMT-A
# <<lst:undo-extnet-setup>>
set -o xtrace
#+END_SRC

*** Teardown script                                                :noexport:
#+BEGIN_SRC bash :noweb tangle :tangle output/teardown.sh :shebang #!/usr/bin/env bash
set -o xtrace

<<lst:undo-extnet-setup>>

sudo snap remove --purge openstackclients
sudo snap remove --purge microstack
#+END_SRC

* Play with OpenStack (as an Admin)
:PROPERTIES:
:CUSTOM_ID: sec:play-with-os
:END:
** OpenStack Horizon dashboard
One service deployed is the OpenStack dashboard (Horizon). On your own
machine, horizon is reachable from the web browser at
[[http://<ip-of-your-lab-machine>]] with the following credentials:
- login: ~admin~
- password: ~keystone~

From here, you can reach ~Project > Compute > Instances > Launch
Instance~ and boot a virtual machine given the following information:
- a name (e.g., ~horizon-vm~)
- an image (e.g., ~cirros~) and set the ~Create New Volume~ to "No"
- a flavor to limit the resources of your instance (we recommend
  ~m1.tiny~)
- and a network setting (must be ~test~)

You should select options by clicking on the big arrow on the right of
each possibility. When the configuration is OK, the ~Launch Instance~
button should be enabled. After clicking on it, you should see the
instance in the ~Active~ state in less than a minute.

Now, you have several options to connect to your freshly deployed VM.
For instance, after clicking on its name, Horizon provides a virtual
console under the ~Console~ tab. So, you can use the following
credentials to access the VM:
- login: ~cirros~
- password: ~gocubsgo~

However, as a /real DevOps/, you will prefer to access to your VM by
the command line interface ...

** Unleash the operator in you
:PROPERTIES:
:CUSTOM_ID: sec:os-cli
:END:
While Horizon is helpful to discover OpenStack features, this is not
the tool of choice for an operator. An operator prefers command line
interface 😄. You are lucky, OpenStack provides one.

All operations to manage OpenStack are done through one unique command
line, called ~openstack <service> <action> ...~. Doing an ~openstack
--help~ displays the /really long/ list of services/possibilities
provided by this command. The following gives you a selection of the
most often used commands to operate your Cloud:
- List OpenStack running services :: ~openstack endpoint list~
- List images :: ~openstack image list~
- List flavors :: ~openstack flavor list~
- List networks :: ~openstack network list~
- List computes :: ~openstack hypervisor list~
- List VMs (running or not) :: ~openstack server list~
- Get details on a specific VM :: ~openstack server show <vm-name>~
- Start a new VM :: ~openstack server create --image <image-name> --flavor <flavor-name> --nic net-id=<net-id> <vm-name>~
- View VMs logs :: ~openstack console log show <vm-name>~

#+BEGIN_do
Try one of these commands. Does it works? What is the problem, how to
fix it? Hint: Look at the [[os-doc:python-openstackclient,cli/authentication.html][password authentication process]] for the CLI.

#+BEGIN_comment
# solution
#+BEGIN_SRC bash
$ openstack endpoint list
Missing value auth-url required for auth plugin password
#+END_SRC

Similarly to Horizon, you have to provide your credentials to the
OpenStack CLI and tell it the URL of the authentication service.
There are *two options* to achieve this.  First, to give them as
arguments of the command.

#+BEGIN_SRC bash
openstack endpoint list --os-auth-url=http://<ip-of-your-lab-machine>:5000/v3/ \
                        --os-username=admin \
                        --os-password=keystone \
                        --os-project-name=admin \
                        --os-user-domain-name=Default \
                        --os-project-domain-id=default
#+END_SRC

This is a bit cumbersome since you have to give them every time.  The
second option consists in seting your credentials as variables in your
bash [[https://www.gnu.org/software/coreutils/manual/html_node/env-invocation.html#env-invocation][environment]].  Hence, the CLI automatically reads these variables
instead.  You can find a pre-generated file with all variables
properly set under the Horizon interface by clicking on the ~admin~
dropdown list at the top right corner, and get the "OpenStack RC
File".

To setup your environment, download and source this file on your Lab
machine.
: source ./admin-openrc.sh

You can then check that your environment is correctly set.
#+BEGIN_SRC bash
$ env|fgrep OS_|sort

OS_AUTH_URL=http://<ip-of-your-lab-machine>:5000/v3/
OS_IDENTITY_API_VERSION=3
OS_INTERFACE=public
OS_PASSWORD=keystone
OS_PROJECT_DOMAIN_ID=default
OS_PROJECT_ID=2bad71b9246a4a06a0c9daf2d8896108
OS_PROJECT_NAME=admin
OS_REGION_NAME=microstack
OS_USER_DOMAIN_NAME=Default
OS_USERNAME=admin
#+END_SRC
#+END_comment
# solution
#+END_do

#+BEGIN_do
Using all these commands, use the CLI to start a new tiny cirros VM
called ~cli-vm~.
#+BEGIN_comment
# solution
#+BEGIN_src bash
openstack server create \
  --image cirros \
  --flavor m1.tiny \
  --network test \
  cli-vm
#+END_src
#+END_comment
# solution
#+END_do

Then, display the information about your VM with the following
command:
: openstack server show cli-vm

Note in particular the ~status~ of your VM (and how to extract that
information from the command line with the ~-c~ and ~-f~).
: openstack server show cli-vm -c status -f json

This status will go from ~BUILD~: OpenStack is looking for the best
place to boot the VM; to ~ACTIVE~: your VM is running. The status
could also be ~ERROR~ if you are experiencing hard times with your
infrastructure.

#+BEGIN_do
What is the purpose of the ~-c~ and ~-f~ argument in the previous
command.
#+BEGIN_comment
# solution
#+BEGIN_example
$ openstack server create --help
...
output formatters:
  output formatter options

  -f {json,shell,table,value,yaml}, --format {json,shell,table,value,yaml}
                        the output format, defaults to table
  -c COLUMN, --column COLUMN
                        specify the column(s) to include, can be repeated
...
#+END_example
#+END_comment
# solution
#+END_do

A VM in ~ACTIVE~ state still has to go through the [[http://www.tldp.org/LDP/intro-linux/html/sect_04_02.html][boot process and
init]]. Hence, you may still have to wait for one minute or two that
your VM finishes to boot. You can check that your VM finished to boot
by looking at its logs with ~openstack console log show cli-vm~. A
CirrOS VM finished to boot when last lines are:
#+BEGIN_EXAMPLE
=== cirros: current=0.4.0 latest=0.4.0 uptime=29.16 ===
  ____               ____  ____
 / __/ __ ____ ____ / __ \/ __/
/ /__ / // __// __// /_/ /\ \
\___//_//_/  /_/   \____/___/
   http://cirros-cloud.net


login as 'cirros' user. default password: 'gocubsgo'. use 'sudo' for root.
cli-vm login:
#+END_EXAMPLE

*** Make the world reaches the VM
The [[os-doc:neutron][neutron]] service manage networks in OpenStack.  Neutron
distinguishes, at least two kind of networks.  First, the /project (or
tenant) network/ to provide communication between VMs of the same
project.  Second, the /provider (or external) network/ to provide an
access to the VM from the outside.  With the
previous ~openstack server create~ command, the VM boots with an IP on
the tenant network.  Consequently, you cannot ping your VM from an
external network (e.g., the Lab machine).

#+BEGIN_do
Find the IP address of the ~cli-vm~. Check that you can ping that
address from the ~horizon-vm~ (using the ~Console~ tab in the Horizon
dashboard).  Ensure that you *cannot* ping that VM from the Lab machine.

#+BEGIN_comment
# solution
#+BEGIN_SRC bash
PRIV_IP=$(openstack server show cli-vm -c addresses -f value | sed -E 's/test=(.+)/\1/g')
echo "Private IP of cli-vm is ${PRIV_IP}"
ping -c 3 "${PRIV_IP}" # From horizon-vm: 0% packet loss, From lab: 100% packet loss
#+END_SRC
#+END_comment
# solution
#+END_do

To ping your VM from the Lab machine, you have to affect it an IP
address of the ~external~ network.  The management of the external
network is done typically at the level of the infrastructure and not
by OpenStack.  OpenStack allows to access IP addresses of that network
using /floating IPs/.  A floating IP is not allocated to a specific VM
by default. Rather, an operator has to explicitly /pick/ one from a
pool and then attach it to its VM. Thus, if the VM dies for some
reason, the operator does not lose the floating IP -- it remains her
own resource, ready to be attached to another VM.  For instance, OVH
uses that mechanism to assign public IP addresses to VMs.

Affect a floating IP of the ~external~ network to your machine if you
want it to be pingable from the host.
#+BEGIN_SRC bash
ALLOCATED_FIP=$(openstack floating ip create \
  -c floating_ip_address -f value external)
echo "${ALLOCATED_FIP}"
openstack server add floating ip cli-vm "${ALLOCATED_FIP}"
#+END_SRC

Then, ask again for the status of your VM and its IPs.
: openstack server show cli-vm -c status -c addresses

#+BEGIN_do
Ping ~cli-vm~ on its floating IP.
: ping -c 3 "$ALLOCATED_FIP"

Does it work? Why? Hint: OpenStack limits the incomming traffic by
default for security reasons.  The mechanisms to control the traffic
in OpenStack is called [[os-doc:neutron,feature_classification/general_feature_support_matrix.html#operation_Security_Groups][security group]].  Find the command that list the
security group rules of the ~admin~ project. # (i.e., ~openstack
project show admin~).

#+BEGIN_comment
# solution
Regarding security rules, OpenStack is very conservative by default
and prevents ingress and egress traffic. Spot the ~None~ value at ~IP
Protocol~, and ~0.0.0.0/0~ [[https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing][CIDR]] at ~IP Range~, in the result table of
the command that list security group rules of the admin project: These
values should be interpreted as /"~None~ protocol on any (~0.0.0.0/0~)
network is allowed"/.
#+BEGIN_src bash
$ SECGROUP_ID=`openstack security group list --project admin -f value -c ID`
$ openstack security group rule list -c ID -c "IP Protocol" -c "IP Range" $SECGROUP_ID

+--------------------------------------+-------------+-----------+
| ID                                   | IP Protocol | IP Range  |
+--------------------------------------+-------------+-----------+
| 473c2c5e-bd23-4b56-9d33-2276e483ac33 | None        | 0.0.0.0/0 |
| ecd3aa5a-acde-4e9f-9738-14945bcee258 | None        | 0.0.0.0/0 |
| 5b08ae18-ed18-4a82-8382-aa1cfc3effff | None        | ::/0      |
| 9b104d51-61d2-4a0f-bac4-36b5803ac721 | None        | ::/0      |
+--------------------------------------+-------------+-----------+
#+END_src
#+END_comment
# solution

Then, make it work for ~10.20.20.0/24~ network. See examples of
security groups rules in the [[https://docs.openstack.org/neutron/latest/admin/deploy-lb-selfservice.html#verify-network-operation][neutron doc]].

#+BEGIN_comment
# solution
To make it work, you have to setup new rules in the security group of
the ~admin~ project. The following rules allow ICMP packets (for ping)
and TCP on port 22 (for SSH connection) on the VM.
#+BEGIN_src bash
openstack security group rule create $SECGROUP_ID --proto icmp --remote-ip 10.20.20.0/24
openstack security group rule create $SECGROUP_ID --proto tcp --remote-ip 10.20.20.0/24 \
  --dst-port 22
#+END_src
#+END_comment
# solution
#+END_do

Once you succeed to ping the vm, you should also be able to SSH on it.
: ssh -l cirros "$ALLOCATED_FIP"

*** Make the VM reaches the world                                  :noexport:
# *Note for the teacher:* The [[lst:undo-extnet-setup]] code undoes the
# [[https://opendev.org/x/microstack/src/commit/1a25e50a172db7331edf2f836f3c2005222bb4c5/snap-overlay/bin/setup-br-ex#L21-L22][microstack network setup]], so students have to resolve the next
# challenge (i.e., the next ~begin_do~). This bash snippet is tangle
# into [[file:setup.sh]] and could be disable in case of a no
# network-oriented students.
#+NAME: lst:undo-extnet-setup
#+BEGIN_SRC bash :exports none
# Undo the external network setup of `microstack.init --auto`
sysctl -w net.ipv4.ip_forward=0 > /dev/null
extcidr=10.20.20.0/24  # find it with `sudo iptables -t nat -L`
iptables -w -t nat -D POSTROUTING -s $extcidr ! -d $extcidr -j MASQUERADE > /dev/null
#+END_SRC

From the cirros, ping the outside world.
: ping 8.8.8.8  # GOOGLE could you HEAR me?!

#+BEGIN_do
Does it work? Why? To help you in your diagnosis, here is a list of
hints to check:
- Ping the VM and Google *from the Lab machine*. The ping should work
  for both. What does it mean for the Lab machine regarding
  communications between VMs and the Internet?
  #+BEGIN_comment
# solution
  : ping -c 2 $ALLOCATED_FIP; ping -c 2 8.8.8.8
  The ping from the Lab machine works for both the VM and Google.
  Thus, the Lab machine /could be a gateway/ between VMs and the
  Internet.
  #+END_comment
# solution

- Note the IP address of ~$ALLOCATED_FIP~. From which network this IP
  comes? Which NIC serves that network on the Lab machine?
  #+BEGIN_comment
# solution
  : echo "$ALLOCATED_FIP"
  : openstack subnet show external-subnet -c cidr -c allocation_pools
  : ip address | fgrep -B 2 10.20.20
  The IP of the VM comes from the network 10.20.20.0/24, which is
  served on the Lab machine by ~br-ex~.
  #+END_comment
# solution

- Do a ~tcpdump~ on that NIC. Do you see the ICMP packets from
  ~$ALLOCATED_FIP~ that flow over that NIC?
  #+BEGIN_comment
# solution
  : sudo tcpdump -nni br-ex icmp
  The ~tcpdump~ on ~br-ex~ shows ping ~echo request~ packets, but no
  ~echo reply~. So the packets are lost somewhere.... In other words,
  the Lab machine does not play its role of gateway between VMs and
  the Internet.
  #+END_comment
# solution

- Find the route that forward packets to the Internet on Lab machine.
  Do a ~tcpdump~ on the NIC that servers that route. Do you see the
  ICMP packets flow over that NIC?
  #+BEGIN_comment
# solution
  To ensure that something is wrong on the Lab machine regarding its
  role of gateway between VMs and the Internet, let's find the route
  that forwards Google packets out of the Lab machine.
  : $ ip route
  :
  : default via 192.168.121.1 dev eth0 proto dhcp src 192.168.121.77 metric 100
  : 10.20.20.0/24 dev br-ex proto kernel scope link src 10.20.20.1
  : 192.168.121.0/24 dev eth0 proto kernel scope link src 192.168.121.77
  : 192.168.121.1 dev eth0 proto dhcp scope link src 192.168.121.77 metric 100
  The command does not show up an /explicit/ route for ~8.8.8.0/9~
  packets. This means that packets are supposed to flow through the
  /default/ route served by the ~eth0~ NIC on my machine.

  Next, do a ~tcpdump~ on that NIC to see if the ICMP packet go
  through it.
  : sudo tcpdump -nni eth0 icmp
  Nothing appears. So ICMP packet are lost somewhere between ~br-ex~
  and ~eth0~, despite the first hint.

  To put it differently, the Lab machine does not forward the incoming
  traffic on ~br-ex~ to ~eth0~. And this is normal, there is [[https://serverfault.com/questions/749682/ip-forwarding-on-linux-anything-important-to-make-sure-to-do-or-know][no reason]]
  for Linux to enable this by default. However in our case, we have to
  activate it. This is called /Kernel IP Forwarding/, and it could be
  set up with the next command (or ~echo 1 >
  /proc/sys/net/ipv4/ip_forward~).
  : sudo sysctl -w net.ipv4.ip_forward=1

  #+BEGIN_note
  Sometimes activating the kernel IP forwarding is not enough,
  [[http://www.microhowto.info/howto/enable_forwarding_of_ipv4_packets.html#idp17360][especially in case of firewalling]]. A common place to perform packet
  filtering of routed traffic is in the ~FORWARD~ chain of the filter
  table.
  : sudo iptables -t filter -L FORWARD -n

  If a rule drops packet, then it is mandatory to accept them with a
  new rule.
  : iptables -A FORWARD -j ACCEPT
  #+END_note
  #+END_comment
# solution

- After making the packets flow on the second NIC, is everything OK
  with the IP address of the source in the ~tcpdump~ on ~eth0~?
  #+BEGIN_comment
# solution
  From now, the ping of Google from the VM reaches Internet via ~eth0~
  (as seen by ~tcpdump -nni eth0 icmp~). Unfortunately, it still does
  not do the trick, because the packet goes out with the ~10.20.20.*~
  source address. For this reason, Google sees ~ICMP echo request~
  incoming packets from ~10.20.20.*~ and hence, replies ~ICMP echo
  reply~ to ~10.20.20.*~ which does not makes sense out of a private
  network.

  You have to change the source IP of out packet (~10.20.20.*~) to
  gateway's IP (i.e., Your lab machine). The ~iptables~ will then
  automatically change the replied packet's destination IP
  (~<ip-of-your-lab-machine>~) to the original source IP
  (~10.20.20.*~). This process is called a SNAT and you can implement
  it with ~iptables~ (see,
  https://www.systutorials.com/1372/setting-up-gateway-using-iptables-and-route-on-linux/).

  Set up the SNAT with ~iptables~. The following rule should be read
  "In the ~nat~ table, for packets that leave the machine (~-A
  POSTROUTING~) and incoming from network ~10.20.20.0/24~ (~-s~) and
  not at destination of the network ~10.20.20.0/24~ (~! -d~), then
  replace the sender's address by the router's address (~-j
  MASQUERADE~)."
  # : sudo iptables -t nat -A POSTROUTING ! -d 10.20.20.0/24 -o <NIC-of-your-lab-machine> -j SNAT --to-source <ip-of-your-lab-machine>
  : sudo iptables -t nat -A POSTROUTING -s 10.20.20.0/24 ! -d 10.20.20.0/24 -j MASQUERADE
  #+END_comment
# solution
#+END_do

Go on, and play with the ~openstack~ cli. For instance, list all
features offered by Nova with ~openstack server --help~ and try to
figure out how to:
1. SSH on ~cli-vm~ using its name rather than its IP;
2. Suspend and resume it;
3. Create a snapshot of ~cli-vm~;
4. Boot a new machine ~cli-vm-clone~ from the snapshot.
5. Delete ~cli-vm-clone~;

#+BEGIN_comment
# solution
#+BEGIN_SRC bash
# 1.
openstack server ssh cli-vm -l cirros
# 2.
openstack server suspend cli-vm; openstack server show cli-vm -c status
openstack server resume cli-vm; openstack server show cli-vm -c status
# 3.
openstack server image create --name cli-vm-img cli-vm; openstack image list
# 4.
openstack server create --wait --flavor m1.tiny \
  --network test --image cli-vm-img \
  cli-vm-clone
# 5.
openstack server delete cli-vm-clone
#+END_SRC
#+END_comment
# solution

** In encryption we trust
:PROPERTIES:
:CUSTOM_ID: sec:enc-trust
:END:
Any cirros VMs share the same credentials (i.e., ~cirros~, ~gocubsgo~)
which is a security problem. As a IaaS DevOps, you want that only some
clients can SSH on the VMs. Fortunately, OpenStack helps with the
management of SSH keys. OpenStack can generate a SSH key and push the
public counterpart on the VM. Therefore, doing a ~ssh~ on the VM will
use the SSH key instead of asking the client to fill the credentials.

Make an SSH key and store the private counterpart in =./admin.pem=.
Then, give that file the correct permission access.
: openstack keypair create --private-key ./admin.pem admin
: chmod 600 ./admin.pem

Start a new VM and ask OpenStack to copy the public counterpart of
your SSH key in the =~/.ssh/authorized_keys= of the VM (i.e., note the
~--key-name admin~).
#+BEGIN_SRC bash
openstack server create --wait --image cirros \
  --flavor m1.tiny --network test \
  --key-name admin cli-vm-adminkey
#+END_SRC

Attach it a floating IP.
#+BEGIN_SRC bash
openstack server add floating ip \
  cli-vm-adminkey \
  $(openstack floating ip create -c floating_ip_address -f value external)
#+END_SRC

Now you can access your VM using SSH without filling credentials.
#+BEGIN_SRC bash
openstack server ssh cli-vm-adminkey \
  --login cirros \
  --identity ./admin.pem
#+END_SRC

#+BEGIN_note
Or directly with the ~ssh~ command --- for bash lovers ❤.
: ssh -i ./admin.pem -l cirros $(openstack server show cli-vm-adminkey -c addresses -f value | sed  -Er 's/test=.+ (10\.20\.20\.[0-9]+).*/\1/g')

A regular ~ssh~ command looks like ~ssh -i <identity-file> -l <name>
<server-ip>~. The OpenStack command followed by the ~sed~ returns the
floating IP of ~cli-vm-adminkey~. You may have to adapt it a bit
according to your network cidr.
: openstack server show cli-vm-adminkey -c addresses -f value | sed  -Er 's/test=.+ (10\.20\.20\.[0-9]+).*/\1/g'
#+END_note

** The art of contextualizing a VM
Contextualizing is the process that automatically installs software,
alters configurations, and does more on a machine as part of its boot
process. On OpenStack, contextualizing is achieved thanks to
[[https://cloud-init.io/][~cloud-init~]]. It is a program that runs at the boot time to customize
the VM.

You have already used ~cloud-init~ without even knowing it! The
previous command ~openstack server create~ with the ~--identity~
parameter tells OpenStack to make the public counterpart of the SSH
key available to the VM. When the VM boots for the first time,
~cloud-init~ is (among other tasks) in charge of fetching this public
SSH key from OpenStack, and copy it to =~/.ssh/authorized_keys=.
Beyond that, ~cloud-init~ is in charge of many aspects of the VM
customization like mounting volume, resizing file systems or setting
an hostname (the list of ~cloud-init~ modules can be found [[http://cloudinit.readthedocs.io/en/latest/topics/modules.html][here]]).
Furthermore, ~cloud-init~ is able to run a bash script that will be
executed on the VM as ~root~ during the boot process.

*** Debian 10 FTW
:PROPERTIES:
:CUSTOM_ID: sec:debian10-ftw
:END:
When it comes the time to deal with real applications, we cannot use
cirros VMs anymore. A Cirros VM is good for testing because it starts
fast and has a small memory footprint. However, do not expect to
launch [[https://en.wikipedia.org/wiki/MariaDB][MariaDB]] or even [[https://github.com/busyloop/lolcat][~lolcat~]] on a cirros.

We are going to run several Debian10 VMs in this section. But, a
Debian10 takes a lot more of resources to run. For this reason, you may
want to release all your resources before going further.

#+NAME: lst:delete-rscs
#+BEGIN_SRC bash
# Delete VMs
for vm in $(openstack server list -c ID -f value); do \
  echo "Deleting ${vm}..."; \
  openstack server delete "${vm}"; \
done

# Releasing floating IPs
for ip in $(openstack floating ip list -c "Floating IP Address" -f value); do \
  echo "Releasing ${ip}..."; \
  openstack floating ip delete "${ip}"; \
done
#+END_SRC

Then, download the Debian10 image with support of ~cloud-init~.
#+BEGIN_SRC bash
curl -L -o /tmp/debian-10.qcow2 \
  https://cloud.debian.org/images/cloud/OpenStack/current-10/debian-10-openstack-amd64.qcow2
#+END_SRC

#+BEGIN_do
Import the image into Glance; name it ~debian-10~. Use ~openstack image
create --help~ for creation arguments. Find values example with
~openstack image show cirros~.
#+BEGIN_comment
# solution
#+BEGIN_SRC bash
openstack image create --disk-format=qcow2 \
  --container-format=bare --property architecture=x86_64 \
  --public --file /tmp/debian-10.qcow2 \
  debian-10
#+END_SRC
#+END_comment
# solution

And, create a new ~m1.mini~ flavor with 5 Go of Disk, 2 Go of RAM, 2
VCPU and 1 Go of swap. Use ~openstack flavor create --help~ for
creation arguments.
#+BEGIN_comment
# solution
#+BEGIN_SRC bash
openstack flavor create --ram 2048 \
  --disk 5 --vcpus 2 --swap 1024 \
  --public m1.mini
#+END_SRC
#+END_comment
# solution
#+END_do

*** ~cloud-init~ in Action
:PROPERTIES:
:CUSTOM_ID: sec:cloud-init
:END:
To tell ~cloud-init~ to load and execute a specific script at boot
time, you should append the ~--user-data <file/path/of/your/script>~
extra argument to the regular ~openstack server create~ command.

#+BEGIN_do
Start a new VM named ~art-vm~ based on the ~debian-10~ image and the
~m1.mini~ flavor. The VM should load and execute the script [[lst:art.sh]]
-- available under ~rsc/art.sh~ -- that installs the [[https://github.com/cmatsuoka/figlet][~figlet~]] and
[[https://github.com/busyloop/lolcat][~lolcat~]] softwares on the VM.

#+BEGIN_comment
# solution
#+BEGIN_SRC bash
openstack server create --wait --image debian-10 \
  --flavor m1.mini --network test \
  --key-name admin \
  --user-data ./rsc/art.sh \
  art-vm
#+END_SRC
#+END_comment
# solution
#+END_do

#+CAPTION: ~cloud-init~ script available under ~rsc/art.sh~
#+NAME: lst:art.sh
#+BEGIN_SRC bash :tangle output/rsc/art.sh
#!/usr/bin/env bash
# Fix DNS resolution
echo "" > /etc/resolv.conf
echo "nameserver 8.8.8.8" >> /etc/resolv.conf

# Install figlet and lolcat
apt update
apt install -y figlet lolcat
#+END_SRC

You can follow the correct installation of software with:
: watch openstack console log show --lines=20 art-vm

#+BEGIN_do
Could you notice /when/ the VM has finished to boot based on the
~console log~ output?  Write a small bash script that waits until the
boot has finished.

#+BEGIN_comment
# solution
#+BEGIN_src bash :tangle output/rsc/wordpress-deploy.sh :shebang #!/usr/bin/env bash
function wait_contextualization {
  # VM to get the log of
  local vm="$1"
  # Number of rows displayed by the term
  local term_lines=$(tput lines)
  # Number of log lines to display is min(term_lines, 20)
  local console_lines=$(($term_lines<22 ? $term_lines - 2 : 20))
  # Get the log
  local console_log=$(openstack console log show --lines=${console_lines} "${vm}")

  # Do not wrap long lines
  tput rmam

  # Loop till cloud-init finished
  local cloudinit_end_rx="Cloud-init v\. .\+ finished"
  echo "Waiting for cloud-init to finish..."
  echo "Current status is:"
  while ! echo "${console_log}"|grep -q "${cloudinit_end_rx}"
  do
      echo "${console_log}"
      sleep 5

      # Compute the new console log before clearing
      # the screen is it does not remain blank for two long.
      local new_console_log=$(openstack console log show --lines=${console_lines} "${vm}")

      # Clear the screen (`cuu1` move cursor up by one line, `el`
      # clear the line)
      while read -r line; do
          tput cuu1; tput el
      done <<< "${console_log}"

      console_log="${new_console_log}"
  done

  # cloud-init finished
  echo "${console_log}"|grep --color=always "${cloudinit_end_rx}"

  # Re-enable wrap of long lines
  tput smam
}
#+END_src

Then use it as the following.
: wait_contextualization art-vm
#+END_comment
# solution
#+END_do

Then, attach it a floating IP.
#+BEGIN_SRC bash
openstack server add floating ip \
  art-vm \
  $(openstack floating ip create -c floating_ip_address -f value external)
#+END_SRC

Hence, you can jump on the VM and call the ~figlet~ and ~lolcat~
software.
#+BEGIN_example
$ openstack server ssh art-vm \
    --login debian \
    --identity ./admin.pem

The authenticity of host '10.20.20.13 (10.20.20.13)' can't be established.
ECDSA key fingerprint is SHA256:WgAn+/gWYg9MkauihPyQGwC0LJ8sLWM/ySrUzN8cK9w.
Are you sure you want to continue connecting (yes/no)? yes

debian@art-vm:~$ figlet "The Art of Contextualizing a VM" | lolcat
#+END_example

** Run VMs at (near-)native speed
Every time you do an ~openstack server create ...~, your request hits,
at some point, the ~nova~ services. It starts by the ~nova-api~ that
processes the REST request. The API, in turns, calls the
~nova-conductor~ that orchestrates the boot: performs some checks,
finds eligible computes and chooses one to transmit the boot order to
its ~nova-compute~. Finally, the ~nova-compute~ asks to the underlying
hypervisor to start the VM.

In your current setup, the hypervisor of your ~nova-compute~ runs
[[https://en.wikipedia.org/wiki/QEMU][QEMU]]. QEMU is a free emulator for hardware virtualization. It supports
a large variety of guest operating systems, but the emulation is a bit
slow. Fortunately, QEMU can be used with [[http://www.linux-kvm.org/][KVM]] to run virtual machines
at near-native speed. KVM (Kernel-based Virtual Machine) is a free
full virtualization solution for Linux that takes advantage of x86
hardware extensions (Intel VT or AMD-V).

To check if the x86 of your Lab machine provides hardware
virtualization, execute the following command.
: egrep -c '(vmx|svm)' /proc/cpuinfo
If it outputs a number greater than 0, then proceed with the following
to speed up the VMs execution. Seek the [[https://docs.openstack.org/nova/stein/admin/configuration/hypervisor-kvm.html][Nova documentation]] for some
help.

#+BEGIN_do
- Check that the KVM kernel module is loaded, and load it otherwise.
  #+BEGIN_comment
# solution
  /From the [[https://docs.openstack.org/nova/stein/admin/configuration/hypervisor-kvm.html#for-x86-based-systems][Nova documentation]]/

  Do the following command to list the loaded kernel modules and
  verify that the KVM modules are loaded.
  : lsmod|fgrep kvm
  If the output includes ~kvm_intel~ or ~kvm_amd~, the KVM hardware
  virtualization modules are loaded and your kernel meets the module
  requirements for OpenStack Compute.

  If the output does not show that the KVM module is loaded, run the
  next command.
  : modprobe -a kvm
  : modprobe -a kvm-intel  # for Intel
  : modprobe -a kvm-amd    # for amd
  #+END_comment
# solution

- Change the configuration of ~nova-compute~ hypervisor (file
  ~/var/snap/microstack/common/etc/nova/nova.conf.d/hypervisor.conf~)
  to support KVM and restart it.
  #+BEGIN_comment
# solution
  : NOVA_HYPERV_CONF=/var/snap/microstack/common/etc/nova/nova.conf.d/hypervisor.conf
  : sudo sed -i 's|virt_type.\+|virt_type = kvm|' $NOVA_HYPERV_CONF
  : sudo sed -i 's|cpu_mode.\+|cpu_mode = host-passthrough|' $NOVA_HYPERV_CONF
  : sudo snap restart microstack.nova-compute
  #+END_comment
# solution
#+END_do

Finally, create a new VM such as in the [[#sec:cloud-init][previous section]] and
appreciate how fast your VM displays the ~figlet "The Art of
Contextualizing a VM with KVM" | lolcat~ command.

* Deploy a WordPress as a Service (as a DevOps)
:PROPERTIES:
:CUSTOM_ID: sec:wp-devops
:END:
In the previous sessions, we saw how to boot a VM with OpenStack, and
execute a post-installation script using the ~user-data~ mechanism.
Such mechanism can help us to install software but it is not enough to
deploy a real Cloud application.  Cloud applications are composed of
multiple services that collaborate to deliver the application.  Each
service is in charge of one aspect of the application.  This
separation of concerns brings flexibility.  If a single service is
overloaded, it is common to deploy new units of this service to
balance the load.

Let's take a simple example: [[https://wordpress.org/][WordPress]]! WordPress is a very popular
content management system (CMS) in use on the Web.  People use it to
create websites, blogs or applications.  It is open-source, written in
PHP, and composed of two elements: a Web server (Apache) and database
(MariaDB).  Apache serves the PHP code of WordPress and stores its
information in the database.

Automation is a very important concept for DevOps.  Imagine you have
your own datacenter and want to exploit it by renting WordPress
instances to your customers.  Each time a client rents an instance,
you have to manually deploy it?!  No. It would be more convenient to
automate all the operations. 😎

#+BEGIN_do
As the DevOps of OWPH -- Online WordPress Hosting -- your job is to
automatize the deployment of WordPress on your OpenStack.  To do so,
you have to make a bash script that:

1. Start ~wordpress-db~: a VM that contains the MariaDB database for
   WordPress.
2. Wait until its final deployment (the database is running).
3. Start ~wordpress-app~: a VM that contains a web server and serves
   the Wordpress CMS.
4. Expose ~wordpress-app~ to the world via your Lab machine on a
   specific port (because our floating IPs are not real public IPs and
   thus inaccessible from the world). Something like
   [[http://<ip-of-your-lab>:8080]].
5. Finally, connect with your browser to the WordPress website (i.e.,
   [[http://<ip-of-your-lab>:8080/wp]]) and initializes a new WordPress
   project named ~os-owph~.

The ~rsc~ directory provides bash scripts to deploy the MariaDB
database and web server of WordPress (also in [[*Appendix][Appendix]]). Review it
before going any further (spot the *TODO*).  And ask yourself
questions such as: Does the ~wordpress-db~ VM needs a floating IP in
order to be reached by the ~wordpress-app~ VM?

Also, remind to [[lst:delete-rscs][clean your environment]].

#+BEGIN_comment
# solution
Find the solution in the ~rsc/wordpress-deploy.sh~ script of the
tarball.

First thing first, enable HTTP connections.
#+BEGIN_SRC bash
openstack security group rule create $SECGROUP_ID \
  --proto tcp --remote-ip 0.0.0.0/0 \
  --dst-port 80
#+END_SRC

Then start a VM with the ~wordpress-db~ name, ~debian-10~ image,
~m1.mini~ flavor, ~test~ network and ~admin~ key-pair. Also,
contextualize your VM with the ~rsc/install-mariadb.sh~ script thanks
to the ~--user-data ./rsc/install-mariadb.sh~ option.

#+BEGIN_SRC bash :tangle output/rsc/wordpress-deploy.sh
openstack server create --wait --image debian-10 \
  --flavor m1.mini --network test \
  --key-name admin \
  --user-data ./rsc/install-mariadb.sh \
  wordpress-db

wait_contextualization wordpress-db
#+END_SRC

Next, start a VM with ~wordpress-app~ name, ~debian-10~ image,
~m1.mini~ flavor, ~test~ network and ~admin~ key-pair. Also,
contextualize your VM with the ~rsc/install-wp.sh~ script thanks to
the ~--user-data ./rsc/install-wp.sh~ option. Note that you need to
provide the IP address of the ~wordpress-db~ to this script before
running it.

Set the script with IP address of ~wordpress-db~.
#+BEGIN_SRC bash :tangle output/rsc/wordpress-deploy.sh
sed -i '13s|.*|DB_HOST="'$(openstack server show wordpress-db -c addresses -f value | sed -Er "s/test=//g")'"|' ./rsc/install-wp.sh
#+END_SRC

Then, create ~wordpress-app~.
#+BEGIN_SRC bash :tangle output/rsc/wordpress-deploy.sh :shebang #!/usr/bin/env bash
openstack server create --wait --image debian-10 \
  --flavor m1.mini --network test \
  --key-name admin \
  --user-data ./rsc/install-wp.sh \
  wordpress-app

wait_contextualization wordpress-app
#+END_SRC

Get a floating ip for the VM.
#+BEGIN_SRC bash :tangle output/rsc/wordpress-deploy.sh
WP_APP_FIP=$(openstack floating ip create -c floating_ip_address -f value external)
#+END_SRC

Attach the ~WP_APP_FIP~ floating ip to that VM.
#+BEGIN_SRC bash :tangle output/rsc/wordpress-deploy.sh
openstack server add floating ip wordpress-app "${WP_APP_FIP}"
#+END_SRC

Setup redirection to access your floating ip on port 80.
: sudo iptables -t nat -A PREROUTING -p tcp --dport 8080 -j DNAT --to "${WP_APP_FIP}:80"

Finally, you can reach WordPress on [[http://<ip-of-your-lab>:8080/wp]].

#+BEGIN_note
Optionally, you can do it with an SSH tunnel to access ~10.20.20.*~
from your own machine.
: ssh -NL 8080:<floating-ip>:80 -l root <ip-of-your-lab-machine>

Then, reach WordPress on [[http://localhost:8080/wp]].
#+END_note
#+END_comment
# solution
#+END_do

* Automatize the Deployment with Heat
:PROPERTIES:
:CUSTOM_ID: sec:heat
:END:
[[os-doc:heat][Heat]] is the OpenStack orchestrator: it eats templates (called HOT for
Heat Orchestration Template - which are files written in YAML)
describing the OpenStack infrastructure you want to deploy (e.g. VMs,
networks, storages) as well as software configurations. Then the Heat
engine is in charge of sending the appropriate requests to OpenStack
to deploy the system described in your template (deployments are
called ~stacks~ in Heat). This section manipulates Heat to understand
how to deploy applications on OpenStack. Template snippets in the
following are available under the ~rsc/heat-templates/~ directory. You
may also find interesting examples in the [[os-doc:heat,template_guide/basic_resources.html][Heat documentation]], or on
the [[https://github.com/openstack/heat-templates][heat-templates repository]].


** Preamble
In this last part, the teacher has setup an OpenStack in a DataCenter
(here, on top of Grid'5000) and created member account and project for
each of you (not admin). As a preamble, you should:
- Connect to the Grid'5000 VPN (Sec.\nbsp{}[[#sec:assign-lab]]).
- Go on the [[horizon-url][horizon dashbord]] of teacher's OpenStack and download the
  "OpenStack RC File V3" (Sec.\nbsp{}[[#sec:os-cli]]) on your own machine.
  + user name: your Grid'5000 login
  + password: ~os-imt~
- [[https://github.com/openstack/python-openstackclient/tree/stable/rocky#getting-started][Install the OpenStack CLI]] and [[https://github.com/openstack/python-heatclient/tree/stable/rocky][Heat CLI]] on your own machine.
  # : alias openstack="pipenv run openstack"
- Source the "OpenStack RC File V3".
- Reimport (or maybe recreate) your admin SSH key
  (Sec.\nbsp{}[[#sec:enc-trust]]).
- Download the last version of the Lab resources (Sec.\nbsp{}[[#sec:rscs-lab]]).

Resource names change a bit from previously. Do not hesitate to run
some commands such as the following to know about new names.
- ~openstack network list~
- ~openstack image list~
- ~openstack flavor list~
- ...

** Boot a VM
The simplest HOT template you can declare describes how to boot a VM.
#+BEGIN_SRC yaml :tangle output/rsc/heat-templates/1_boot_vm.yaml
# The following heat template version tag is mandatory:
heat_template_version: 2017-09-01

# Here we define a simple decription of the template (optional):
description: >
  Simply boot a VM!

# Here we declare the resources to deploy.
# Resources are defined by a name and a type which described many properties:
resources:
  # Name of my resource:
  heat-vm:
    # Its type, here we want to define an OpenStack Nova server:
    type: "OS::Nova::Server"
    properties:
      name: hello_world      # Name of the VM
      image: debian-10       # Its image of the VM (must be available in Glance)
      flavor: m1.mini        # Its flavor (must exist in Nova)
      key_name: admin        # Name of the SSH Key (must exist in Nova)
      networks:              # List of networks to connect to
        - {network: private}
#+END_SRC

As depicted in this example, the different OpenStack resources can be
declared using types. OpenStack resource types are listed in the
[[os-doc:heat,template_guide/openstack.html][documentation]], browsing this page, you can see that resources exist
for most OpenStack services (e.g. Nova, Neutron, Glance, Cinder,
Heat). Here, we declare a new resource called ~heat-vm~ which is
defined by the type ~OS::Nova::Server~ to declare a new virtual
machine. A type specifies different properties (some are mandatory,
some are optional, [[os-doc:heat,template_guide/openstack.html][see the documentation]] for more details). The
~OS::Nova::Server~ properties should be familiar to you since it is
the classical properties Nova requires to boot a VM (i.e. name, image,
flavor, key name). Once you have written this template in a file, you
can now deploy the stack as following:
#+BEGIN_SRC bash
openstack stack create -t ./rsc/heat-templates/1_boot_vm.yaml hw1
openstack stack list
openstack stack show hw1
watch openstack server list
openstack stack delete --wait --yes hw1
#+END_SRC

This simple template is enough to run a virtual machine. However, it
is very static. In the next subsection, we are going to manipulate
parameters to add flexibility.

** Need more flexibility: let's add parameters
:PROPERTIES:
:CUSTOM_ID: sec:heat-params
:END:
Templates can be more flexible with parameters. To that end you can:
- Declare a set of parameters to provide to your template.
- Use the [[os-doc:heat,template_guide/hot_spec.html#hot-spec-intrinsic-functions][intrinsic function]] ~get_param~ to map those parameters in
  your resource declarations.

The next template is an example with four parameters. The first one is
related to the VM name and must be provided during the stack creation.
The second one is the name of the VM image with a ~debian-10~ as
default value. The third argument corresponds to the flavor and
defaults to ~m1.small~. Finally, the last one defines the SSH key to
use and defaults to ~admin~.
#+begin_src yaml :tangle output/rsc/heat-templates/2_boot_vm_with_params.yaml
heat_template_version: 2017-09-01

description: >
    Simply boot a VM with params!

# Here we define parameters
# Parameters have a name, and a list of properties:
parameters:
  the_vm_name:
    type: string                     # The type of the parameter (required)
    description: Name of the server  # An optional description
  the_image:
    type: string
    description: Image to use for servers
    default: debian-10               # An optional default value
  the_flavor:
    type: string
    description: Flavor to use for servers
    default: m1.small
  the_key:
    type: string
    description: Key name to use for servers
    default: admin

# Here we use intrinsic functions to get the parameters:
resources:
  heat-vm:
    type: "OS::Nova::Server"
    properties:
      name:     { get_param: the_vm_name }
      image:    { get_param: the_image }
      flavor:   { get_param: the_flavor }
      key_name: { get_param: the_key }
      networks:
        - {network: private}
#+end_src

To deploy this stack, run the next command. It deploys the VM by
overriding the default flavor value ~m1.mini~ with ~m1.small~. This
can be checked in ~openstack server list~.
#+BEGIN_src bash
openstack stack create -t ./rsc/heat-templates/2_boot_vm_with_params.yaml \
  --parameter the_vm_name=hello_params \
  --parameter the_flavor=m1.small \
  hw2
openstack server list
openstack stack delete --wait --yes hw2
#+END_src

The parameter ~the_vm_name~ is required as no default value is
provided. If you try to create a stack without providing this
parameter, you end with an error.
#+BEGIN_SRC bash
openstack stack create -t ./rsc/heat-templates/2_boot_vm_with_params.yaml \
    --parameter the_flavor=m1.medium \
    hw2_error

ERROR: The Parameter (the_vm_name) was not provided.
#+END_SRC

Parameters are the inputs of templates. The next subsection, focuses
on declaring outputs, so that a stack can return a set of
attributes (e.g., the IP address of a deployed VM).

** Need to return values: let's use outputs!
:PROPERTIES:
:CUSTOM_ID: sec:heat-outputs
:END:
Templates can declare a set of attributes to return. For instance, you
might need to know the IP address of a resource at runtime. To that
end, you can declare attributes in a new section called ~outputs~:

#+begin_src yaml :tangle output/rsc/heat-templates/3_boot_vm_with_output.yaml
heat_template_version: 2017-09-01

description: >
  Boot a VM and return its IP address!

resources:
  heat-vm:
    type: "OS::Nova::Server"
    properties:
      name: hello_outputs
      image: debian-10
      flavor: m1.mini
      key_name: admin
      networks:
        - {network: private}

# We set here outputs (stack returned attributes).
# Outputs are defined by a name, and a set of properties:
outputs:
  HOSTIP:
    # The description is optional
    description: IP address of the created instance
    # Use `get_attr` to find the value of `HOSTIP`. The `get_attr`
    # function references an attribute of a resouces, here the
    # `addresses.private[0].addr` of `heat-vm`.
    #
    # The following should be read:
    # - on `heat-vm` resource (which is an object ...)
    # - select the `addresses` attribute (which is an object ...)
    # - select the `private` attribute (which is a list ...)
    # - pick the element at indices `0` (which is an object ...)
    # - select the `addr` attribute (which is a string)
    value: { get_attr: [heat-vm, addresses, private, 0, addr] }
  HOSTNAME:
    description: Hostname of the created instance
    value: { get_attr: [heat-vm, name] }
#+end_src

The template declares an output attribute called ~HOSTIP~ which stores
the IP address of the VM resource. To find the IP address, it uses
another [[os-doc:heat,template_guide/hot_spec.html#get-attr][intrinsic function]]: ~get_attr~. Same with the ~HOSTNAME~
output. Output attributes can be exploited in two ways: they can be
displayed from the CLI, or they can be fetched by other stack
templates (we will see this last case latter):

#+begin_src bash
openstack stack create -t ./rsc/heat-templates/3_boot_vm_with_output.yaml hw3
openstack stack output list hw3
openstack stack output show hw3 HOSTIP
#+end_src

#+begin_note
Once again, the Heat documentation is your friend to find out
[[os-doc:heat,template_guide/openstack.html#OS::Nova::Server-attrs][attributes]]. As such, you can reference the IP address with the
~network~ attribute.
: get_attr: [heat-vm, networks, private, 0]

The source code of Heat also list [[https://github.com/openstack/heat/blob/0703ca7bb19ca3bb06009c828a66bababf9970b8/heat/engine/resources/openstack/nova/server.py#L646-L736][extra attributes]] that lets you find
the IP address such as ~first_address~, but that one is deprecated
though.
: get_attr: [heat-vm, networks, private, 0]
: get_attr: [heat-vm, first_address]

Finally, you can introspect all attributes of a resource with the
following command at runtime:
: python -c "import pprint; pprint.pprint($(openstack stack resource show hw3 heat-vm -c attributes -f value))"

#+begin_src python
{u'OS-DCF:diskConfig': u'MANUAL',
 # ...
 u'addresses': {u'private': [{u'OS-EXT-IPS-MAC:mac_addr': u'fa:16:3e:73:10:fe',
                           u'OS-EXT-IPS:type': u'fixed',
                           u'addr': u'192.168.222.84',
                           u'version': 4}]},
 # ...
 u'image': {u'id': u'3c91bbf5-5d1f-4e72-bf77-6dbc19c8351c',
            u'links': [{u'href': u'http://10.20.20.1:8774/images/3c91bbf5-5d1f-4e72-bf77-6dbc19c8351c',
                        u'rel': u'bookmark'}]},
 # ...
 u'name': u'hello_outputs'}
#+end_src
#+end_note

Remember to delete your stack at the end to release resources.
: openstack stack delete --wait --yes hw3

** Integrate ~cloud-init~
It is possible to declare a post-installation script in the template
with the ~user_data~ property.
#+begin_src yaml :tangle output/rsc/heat-templates/4_boot_vm_with_user-data.yaml
heat_template_version: 2017-09-01

description: >
  Boot a VM with a post-installation script!

resources:
  heat-vm:
    type: "OS::Nova::Server"
    properties:
      name: hello_cloud_init
      image: debian-10
      flavor: m1.mini
      key_name: admin
      networks:
        - {network: private}
      # We set here the user-data:
      user_data: |
        #!/usr/bin/env bash

        # Fix DNS resolution
        echo "" > /etc/resolv.conf
        echo "nameserver 8.8.8.8" >> /etc/resolv.conf

        # Install stuff and configure the MOTD
        apt-get update
        apt-get install -y fortune fortunes cowsay lolcat
        echo "#!/usr/bin/env bash" > /etc/profile.d/cowsay.sh
        echo "fortune | cowsay -n | lolcat" >> /etc/profile.d/cowsay.sh
#+end_src

: openstack stack create -t ./rsc/heat-templates/4_boot_vm_with_user-data.yaml hw4

Associating a floating IP is a bit tricky with Heat, so let's do it
manually for now. Then, wait for ~cloud-init~ to finish and finally,
SSH on the VM (the ~wait_contextualization~ function comes from
section [[#sec:cloud-init]]).

#+begin_src bash
openstack server add floating ip hello_cloud_init \
  $(openstack floating ip create -c floating_ip_address -f value public)
wait_contextualization hello_cloud_init
openstack server ssh --login debian --identity ./admin.pem hello_cloud_init
openstack stack delete --wait --yes hw4
#+end_src

#+BEGIN_note
Find the ~user_data~ file executed on the VM by cloud-init at
~/var/lib/heat-cfntools/cfn-userdata~. This path comes from the log of
the VM boot (using ~openstack console log show hello_cloud_init~)
right after the log ~Cloud-init v. ... running~.
#+END_note

** Dynamic configuration with ~cloud-init~ and parameters
Let's mix parameters and cloud-init to write a template with a
flexible post-installation script. With Heat, it is possible to
provide a parameter to your user-data at run-time by using a new
[[os-doc:heat,template_guide/hot_spec.html#str-replace][intrinsic function]]: ~str_replace~.

#+begin_src yaml :tangle output/rsc/heat-templates/5_boot_vm_with_user-data2.yaml
heat_template_version: 2017-09-01

description: >
  Boot a VM by installing a set of packages given as parameters!

parameters:
  package-names:
    label: List of packages to install
    type: string

resources:
  heat-vm:
    type: "OS::Nova::Server"
    properties:
      name: hello_cloud_init_params
      image: debian-10
      flavor: m1.mini
      key_name: admin
      networks:
        - {network: private}
      user_data:
        # This intrinsic function can replace strings in a template
        str_replace:
          # We define here the script
          template: |
              #!/usr/bin/env bash
              apt-get update
              apt-get install -y ${PKG-NAMES}
          # We define here the parameters for our script
          params:
            ${PKG-NAMES}: { get_param: package-names }
#+end_src

The template uses ~str_replace~ to instantiate variables in the
template. In this example, the parameter should be a string containing
a set of packages to install in the VM. You can deploy the stack as
follow:
#+BEGIN_SRC bash
openstack stack create \
    -t ./rsc/heat-templates/5_boot_vm_with_user-data2.yaml \
    --parameter package-names="vim cowsay fortune fortunes lolcat" \
   hw5
openstack stack delete --wait --yes hw5
#+END_SRC

This mechanism is crucial to dynamically configure our services during
the deployment. For instance, ~service-A~ might require an IP address
in its configuration file to access ~service-B~, which runs on another
VM. This IP address is only known at run-time, so it must be
represented by a variable managed in Heat templates. In the next
subsections, we are going to study how to declare such variable, so
that Heat resources can exchange information.

** Data dependency between resources
:PROPERTIES:
:CUSTOM_ID: sec:data-deps-rscs
:END:
Let's declare a template with two VMs: ~user~ and ~provider~. The idea
is to configure ~user~'s static lookup table for hostnames (more
information can be found by typing: ~man hosts~), so that user can
target ~provider~ from its hostname rather than its IP address. To
that end, the template uses the ~user_data~ property together with the
~get_attr~ function to edit the ~/etc/hosts~ file on ~user~, and map
the IP address of ~provider~ with its hostname.

#+begin_src yaml :tangle output/rsc/heat-templates/6_boot_vms_with_exchange.yaml
heat_template_version: 2017-09-01

description: >
  Boot two VMs and ease the access from user to provider!

resources:
  user-vm:
    type: "OS::Nova::Server"
    properties:
      name: user
      image: debian-10
      flavor: m1.mini
      key_name: admin
      networks:
        - {network: private}
      user_data:
        str_replace:
          template: |
            #!/usr/bin/env bash
            # With the following line, provider is reachable from its hostname
            echo "${IP_ADDRESS} provider" >> /etc/hosts
          params:
            # `get_attr` references the following `provider-vm` resource.
            ${IP_ADDRESS}: { get_attr: [provider-vm, addresses, private, 0, addr] }

  provider-vm:
    type: "OS::Nova::Server"
    properties:
      name: provider
      image: debian-10
      flavor: m1.mini
      key_name: admin
      networks:
        - {network: private}
#+end_src

In this example, ~user~ requires the IP address of ~provider~ to boot.
The Heat engine is in charge of managing dependencies between
resources. Take a look during the deployment, and check that
~provider~ is deployed prior to ~user~.

#+BEGIN_EXAMPLE
openstack stack create -t ./rsc/heat-templates/6_boot_vms_with_exchange.yaml hw6 \
  && watch openstack server list
openstack server add floating ip user \
  $(openstack floating ip create -c floating_ip_address -f value public)
openstack server ssh --login debian --identity ./admin.pem --address-type public user
debian@user:~$ ping provider -c 2
PING provider-vm (192.168.222.238) 56(84) bytes of data.
64 bytes from provider (192.168.222.238): icmp_seq=1 ttl=64 time=1.27 ms
64 bytes from provider (192.168.222.238): icmp_seq=2 ttl=64 time=3.07 ms

debian@user:~$ exit
openstack stack delete --wait --yes hw6
#+END_EXAMPLE

** Nested templates
Heat is able to compose templates to keep human-readable files, using
nested templates. For instance, we can use a first template that
describes a virtual machine, and a second template which deploys
multiple VMs by referencing the first one. Rather than creating the
first template, we can re-use the one from section [[#sec:heat-params]].

#+begin_src yaml :tangle output/rsc/heat-templates/7_nested_template.yaml
heat_template_version: 2017-09-01

description: >
  Boot two different VMs by exploiting nested templates!

resources:
  provider-vm:
    # Template can be provided as resource type (relatively to
    # that template)
    type: ./2_boot_vm_with_params.yaml
    # The related properties are given as template's parameters:
    properties:
      the_vm_name: provider
      the_flavor: m1.mini

  user-vm:
    type: ./2_boot_vm_with_params.yaml
    properties:
      the_vm_name: user
#+end_src

To compose template, a new resource can be defined by specifying its
type as the target of the desired template. A set of properties can be
provided to the nested template and will be interpreted as parameters.

#+BEGIN_src bash
openstack stack create -t ./rsc/heat-templates/7_nested_template.yaml hw7 \
  && watch openstack server list
openstack stack delete --wait --yes hw7
#+END_SRC

Nested templates are very convenient to keep your code clean and
re-usable. Next section extends nested templates with data
dependency.

** Nested templates with data dependency
Let's describe the same deployment as in section [[#sec:data-deps-rscs]]
by using nested templates. For that we need a new template:

#+begin_src yaml :tangle output/rsc/heat-templates/8_nested_template_boot_vm.yaml
heat_template_version: 2017-09-01

description: >
  Boot a VM, ease access to a remote host and return its IP address!

parameters:
  the_vm_name:
    type: string
    description: Name of the server
  the_remote_hostname:
    type: string
    description: Host name of the remote host
    default: provider
  the_remote_ip:
    type: string
    description: IP address of the remote host

resources:
  hostname-vm:
    type: "OS::Nova::Server"
    properties:
      name:     { get_param: the_vm_name }
      image:    debian-10
      flavor:   m1.mini
      key_name: admin
      networks:
        - {network: private}
      user_data:
        str_replace:
          params:
            ${HOSTNAME}: { get_param: the_remote_hostname }
            ${IP_ADDRESS}: { get_param: the_remote_ip }
          template: |
            #!/usr/bin/env bash
            # With the following line, the remote host is reachable from its hostname
            echo "${IP_ADDRESS} ${HOSTNAME}" >> /etc/hosts

outputs:
  HOSTIP:
    description: IP address of the created instance
    value: { get_attr: [hostname-vm, networks, private, 0] }
#+end_src

We can now declare the main template. While it defines three VMs, this
template is easy to read since it points to the template created
previously and template in section [[#sec:heat-outputs]].
#+begin_src yaml :tangle output/rsc/heat-templates/8_nested_template_exchange.yaml
heat_template_version: 2017-09-01

description: >
  Boot three VMs and ease the access to provider using nested
  templates!

resources:
  provider-vm:
    type: ./3_boot_vm_with_output.yaml

  user-vm1:
    type: ./8_nested_template_boot_vm.yaml
    properties:
      the_vm_name: user1
      the_remote_ip: { get_attr: [provider-vm, HOSTIP] }
      the_remote_hostname: { get_attr: [provider-vm, HOSTNAME] }

  user-vm2:
    type: ./8_nested_template_boot_vm.yaml
    properties:
      the_vm_name: user2
      the_remote_ip: { get_attr: [provider-vm, HOSTIP] }
      the_remote_hostname: { get_attr: [provider-vm, HOSTNAME] }
#+end_src

# FIXME: At some point, something like that should prevenet me to add
# a HOSTNAME in [[#sec:heat-outputs]] template. I have to look at it next
# time.
# : the_remote_hostname: { get_attr: [provider-vm, resources.heat-vm, name] }

#+BEGIN_src bash
openstack stack create -t ./rsc/heat-templates/8_nested_template_exchange.yaml hw8 \
  && watch openstack server list
openstack stack delete --wait --yes hw8
#+END_SRC

** Other type of resources: floating IP
It's Floating IP time!

#+BEGIN_SRC yaml :tangle output/rsc/heat-templates/9_floating_ip.yaml
heat_template_version: 2017-09-01

description: >
  Boot a VM and associate a floating IP.

resources:
  server:
    type: OS::Nova::Server
    properties:
      name: hello_fip
      image: debian-10
      flavor: m1.mini
      key_name: admin
      networks:
        - {network: private}

  floating-ip:
    type: OS::Neutron::FloatingIP
    properties:
      floating_network: public

  association:
    type: OS::Neutron::FloatingIPAssociation
    properties:
      floatingip_id: { get_resource: floating-ip }
      port_id: { get_attr: [server, addresses, private, 0, port]}
#+END_SRC

: openstack stack create -t ./rsc/heat-templates/9_floating_ip.yaml --wait hw9

You may find the floating IP by listing servers.
: openstack server list
Or by asking Heat about attributes of the ~floating-ip~ resource.
#+BEGIN_src bash
FIP_RSC_ATTRIBUTES=$(openstack stack resource show -c attributes -f value hw9 floating-ip)
python -c "print('floating ip is %s' % ${FIP_RSC_ATTRIBUTES}['floating_ip_address'])"
#+END_src

Remember to delete your stack at the end to release resources.
: openstack stack delete --wait --yes hw9

* Deploy a WordPress as a Service (as a Heat DevOps)
:PROPERTIES:
:CUSTOM_ID: sec:wp-heat
:END:
As a DevOps at OWPH -- Online WordPress Hosting -- you are now in
charge of the automation process of deploying WordPress instances for
clients: Congratulation! To that end, you have to use what you learned
from the previous section to design a template that describes a
WordPress application using Heat. We are going to deploy WordPress
inside two VMs: the first one holds the web server, the second one
runs the database:

- VM1: Apache + PHP + WordPress code
- VM2: MariaDB

#+BEGIN_do
Create three HOT files:

- ~db-vm.yml~  :: Contains the description of the VM running MariaDB.
- ~wp-vm.yml~  :: Contains the description of the VM running the Web
                  server and serving Wordpress ;
- ~wp-app.yml~ :: Contains the description of the WordPress
                  application (glues the ~db-vm.yml~ and ~web-vm.yml~
                  together).

Once it is deployed, you should be able to reach the wordpress service by
going on [[http://<web-server-fip-address>/wp]].

#+BEGIN_comment
# solution

Find the solution in the ~rsc/heat-templates/wordpress/~ directory of
the tarball and in the following subsections.

#+END_comment
# solution
#+END_do

** Database VM template                                            :solution:
#+BEGIN_src yaml :tangle output/rsc/heat-templates/wordpress/db-vm.yaml
heat_template_version: 2017-09-01

description: >
  Deploy an MariaDB server, outputs its IP address.

parameters:
  ServerKeyName:
    label: Name of the SSH key to provide to cloud-init
    type: string
    default: admin

  # Parameters used in the cloud-init script to install & configure
  # MariaDB.
  DBRootPassword:
    label: Value of the password to manage the database
    type: string
  DBName:
    label: Name of the database to create
    type: string
  DBUser:
    label: Name of the database user
    type: string
  DBPassword:
    label: Password to access the database
    type: string

resources:
  db-vm:
    type: OS::Nova::Server
    properties:
      key_name: { get_param: ServerKeyName }
      image: debian-10
      flavor: m1.mini
      networks:
        - {network: private}
      user_data:
        str_replace:
          template: { get_file: ../../install-mariadb.sh }
          params:
            ${DB_ROOTPASSWORD}: { get_param: DBRootPassword }
            ${DB_NAME}: { get_param: DBName }
            ${DB_USER}: { get_param: DBUser }
            ${DB_PASSWORD}: { get_param: DBPassword }
outputs:
  DBHost:
    description: IP address of the created instance running MariaDB
    value: { get_attr: [db-vm, networks, private, 0] }
#+END_src

** Web VM template                                                 :solution:
#+BEGIN_src yaml :tangle output/rsc/heat-templates/wordpress/wp-vm.yaml
heat_template_version: 2017-09-01

description: >
  Deploy an HTTP server that serves WordPress. Requires an SQL
  database, whose IP address must be provided as a parameter.

parameters:
  ServerKeyName:
    label: Name of the SSH key to provide to cloud-init
    type: string
    default: admin

  # Parameters used in the cloud-init script to install & configure
  # the WordPress app.
  DBName:
    label: Name of the database to use
    type: string
  DBUser:
    label: Name of the database user
    type: string
  DBPassword:
    label: Password to access the database
    type: string
  DBHost:
    label: IP address of the SQL server
    type: string

resources:
  wp-vm:
    type: OS::Nova::Server
    properties:
      key_name: { get_param: ServerKeyName }
      image: debian-10
      flavor: m1.mini
      networks:
        - {network: private}
      user_data:
        str_replace:
          template: { get_file: ../../install-wp.sh }
          params:
            ${DB_NAME}:     { get_param: DBName }
            ${DB_USER}:     { get_param: DBUser }
            ${DB_PASSWORD}: { get_param: DBPassword }
            ${DB_HOST}:     { get_param: DBHost }

  floating-ip:
    type: OS::Neutron::FloatingIP
    properties:
      floating_network: public

  association:
    type: OS::Neutron::FloatingIPAssociation
    properties:
      floatingip_id: { get_resource: floating-ip }
      port_id: { get_attr: [wp-vm, addresses, private, 0, port]}
#+END_src

** Wordpress application template                                  :solution:
#+BEGIN_src yaml :tangle output/rsc/heat-templates/wordpress/wp-app.yaml
heat_template_version: 2017-09-01

description: >
  Deploy a WordPress application, composed of an SQL
  instance and an HTTP instance that serves WordPress.


parameters:
  ServerKeyName:
    label: Name of the SSH key to provide to cloud-init
    type: string
    default: admin

  # Parameters used in the cloud-init script to install & configure
  # MariaDB
  DBRootPassword:
    label: Value of the password to manage the database
    type: string
    default: 0p3nSt4cK
  DBName:
    label: Name of the database to create
    type: string
    default: wordpress
  DBUser:
    label: Name of the database user
    type: string
    default: donatello
  DBPassword:
    label: Password to access the database
    type: string
    default: leonardo

resources:
  database:
    type: ./db-vm.yaml
    properties:
      ServerKeyName: { get_param: ServerKeyName }
      DBRootPassword: { get_param: DBRootPassword }
      DBName: { get_param: DBName }
      DBUser: { get_param: DBUser }
      DBPassword: { get_param: DBPassword }
  wordpress:
    type: ./wp-vm.yaml
    properties:
      ServerKeyName: { get_param: ServerKeyName }
      DBName: { get_param: DBName }
      DBUser: { get_param: DBUser }
      DBPassword: { get_param: DBPassword }
      DBHost: { get_attr: [database, DBHost] }
#+END_src

* Appendix
** Install MariaDB on Debian 10
#+BEGIN_src bash :tangle output/rsc/install-mariadb.sh
#!/usr/bin/env bash
#
# Install and configure MariaDB for Debian 10.

# Fix DNS resolution
echo "" > /etc/resolv.conf
echo "nameserver 8.8.8.8" >> /etc/resolv.conf

# Parameters
DB_ROOTPASSWORD=root
DB_NAME=wordpress    # Wordpress DB name
DB_USER=silr         # Wordpress DB user
DB_PASSWORD=silr     # Wordpress DB pass

# Install MariaDB
apt update -q
apt install -q -y mariadb-server mariadb-client

# Next line stops mysql install from popping up request for root password
export DEBIAN_FRONTEND=noninteractive
sed -i 's/127.0.0.1/0.0.0.0/' /etc/mysql/mariadb.conf.d/50-server.cnf
systemctl restart mysql

# Setup MySQL root password and create a user and add remote privs to app subnet
mysqladmin -u root password ${DB_ROOTPASSWORD}

# Create the wordpress database
cat << EOSQL | mysql -u root --password=${DB_ROOTPASSWORD}
FLUSH PRIVILEGES;
CREATE USER '${DB_USER}'@'localhost';
CREATE DATABASE ${DB_NAME};
SET PASSWORD FOR '${DB_USER}'@'localhost'=PASSWORD("${DB_PASSWORD}");
GRANT ALL PRIVILEGES ON ${DB_NAME}.* TO '${DB_USER}'@'localhost' IDENTIFIED BY '${DB_PASSWORD}';
CREATE USER '${DB_USER}'@'%';
SET PASSWORD FOR '${DB_USER}'@'%'=PASSWORD("${DB_PASSWORD}");
GRANT ALL PRIVILEGES ON ${DB_NAME}.* TO '${DB_USER}'@'%' IDENTIFIED BY '${DB_PASSWORD}';
EOSQL
#+END_src

** Install Wordpress application on Debian 10
#+BEGIN_src bash :tangle output/rsc/install-wp.sh
#!/usr/bin/env bash
#
# Install and configure Apache to serve Wordpress for Debian 10.

# Fix DNS resolution
echo "" > /etc/resolv.conf
echo "nameserver 8.8.8.8" >> /etc/resolv.conf

# Parameters
DB_NAME=wordpress
DB_USER=silr
DB_PASSWORD=silr
DB_HOST=TODO

apt-get update -y
apt-get upgrade -y
apt-get install -q -y --force-yes wordpress apache2 curl lynx

cat << EOF > /etc/apache2/sites-available/wp.conf
Alias /wp/wp-content /var/lib/wordpress/wp-content
Alias /wp /usr/share/wordpress
<Directory /usr/share/wordpress>
    Options FollowSymLinks
    AllowOverride Limit Options FileInfo
    DirectoryIndex index.php
    Require all granted
</Directory>
<Directory /var/lib/wordpress/wp-content>
    Options FollowSymLinks
    Require all granted
</Directory>
EOF

a2ensite wp
service apache2 reload

cat << EOF > /etc/wordpress/config-default.php
<?php
define('DB_NAME', '${DB_NAME}');
define('DB_USER', '${DB_USER}');
define('DB_PASSWORD', '${DB_PASSWORD}');
define('DB_HOST', '${DB_HOST}');
define('WP_CONTENT_DIR', '/var/lib/wordpress/wp-content');
?>
EOF
#+END_src
# This is not needed anymore (at least, with SSH tunneling)
# define('WP_SITEURL', 'http://' . $_SERVER['HTTP_HOST'] . '/wp');

* Footnotes
[fn:g5k-tunnel] For sure, you always can setup an SSH tunnel but this
is a bit annoying.
* Variables                                                        :noexport:

#+STARTUP: entitiespretty
#+LANGUAGE: en
#+OPTIONS: ^:{} ':t email:t toc:nil
#+PROPERTY: header-args :mkdirp yes
#+LINK: cdn-url      https://github.com/BeyondTheClouds/lectures/blob/f65ea63/%s?raw=true
#+LINK: horizon-url  http://10.24.61.255

#+EXCLUDE_TAGS: noexport
# #+EXCLUDE_TAGS: solution

# -- HTML specific options
#+OPTIONS: html-link-use-abs-url:nil html-preamble:t html-scripts:t html-style:t html5-fancy:t tex:t
#+HTML_DOCTYPE: html5
#+HTML_CONTAINER: div
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../../../rsc/org.css" />
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../../rsc/org.css" />
#+HTML_HEAD: <style>#table-of-contents .tag {display: none;}</style>

# -- Programmed options
# Local Variables:
# org-html-postamble: "<p class=\"author\">Author: %a</p>
# <p class=\"email\">Email: %e</p>
# <p class=\"github\">Find a typo, wanna make a proposition:
#  <a href=\"https://github.com/BeyondTheClouds/lectures/issues/new?title=[os-imt]\">open an issue</a></p>
# <p class=\"date\">Last modification: %C</p>
# <p class=\"license\">This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
# <p class=\"creator\">%c – <a href=\"http://gongzhitaao.org/orgcss\">Zhitao Gong</a> customized theme</p>"
# eval: (progn
# (defun os-doc (tag)
#           (let* ((split-tag (s-split "," tag))
#                  (os-service (or (-first-item split-tag)
#                                  (error "OpenStack service name is required in %s" tag)))
#                  (os-url     (or (-second-item split-tag) "")))
#             (s-lex-format "https://docs.openstack.org/${os-service}/ussuri/${os-url}")))
# (add-to-list 'org-link-abbrev-alist '("os-doc" . "%(os-doc)"))
# )
# End:
